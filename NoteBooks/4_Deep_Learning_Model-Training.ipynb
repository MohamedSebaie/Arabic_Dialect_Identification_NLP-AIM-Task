{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic_Dialect_Identification_NLP_AIM_Task_M.Sebaie.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sSb5DWUqjuUd",
        "98m2ItehmotF"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic_Dialect_Identification_NLP_AIM_Task\n",
        "**`Mohamed Sebaie Sebaie Youssef`**"
      ],
      "metadata": {
        "id": "IThqS1uQ3gbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing requirements"
      ],
      "metadata": {
        "id": "p1Wg9Kqaop12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install pyarabic"
      ],
      "metadata": {
        "id": "buhSwa7x89Mv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Aim_NLP_Task/Arabic_Dialect_Classification_Task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg_OdJDc3qRj",
        "outputId": "c54e2c04-fe61-4a1c-f52d-260b925ddcf9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Aim_NLP_Task/Arabic_Dialect_Classification_Task\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2363EnV7_yY",
        "outputId": "47676ffd-baa5-404d-aea1-6bb3c0cc5f11"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc \n",
        "import time\n",
        "import aranorm\n",
        "import pandas as pd\n",
        "import dialectUtils\n",
        "import preprocess_arabert\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification,BertTokenizer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "metadata": {
        "id": "-pTBg5KW8D0A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tweets,train_labels = dialectUtils.read_csv(\"../Data/preProcessedTweets_trainF.csv\",\n",
        "                                                  \"text_preprocessed\",\"label\")\n",
        "valid_tweets,valid_labels = dialectUtils.read_csv(\"../Data/preProcessedTweets_validF.csv\",\n",
        "                                                  \"text_preprocessed\",\"label\")\n",
        "test_tweets,test_labels = dialectUtils.read_csv(\"../Data/preProcessedTweets_testF.csv\",\n",
        "                                                  \"text_preprocessed\",\"label\")"
      ],
      "metadata": {
        "id": "DzCKu9Q_wC4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert `Base` AraBert"
      ],
      "metadata": {
        "id": "0pZ4GCrYxrna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train "
      ],
      "metadata": {
        "id": "Tq6Ldi5g77Fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preTrainedBertModel_base=\"aubmindlab/bert-base-arabertv02-twitter\"\n",
        "\n",
        "tokenizer_base= AutoTokenizer.from_pretrained(preTrainedBertModel_base)\n",
        "tokenizer_obj_base = dialectUtils.Tokenizer(tokenizer_base)\n",
        "\n",
        "\n",
        "train_data_base = tokenizer_obj_base.bert_tokenize_data(train_tweets,train_labels)\n",
        "valid_data_base = tokenizer_obj_base.bert_tokenize_data(valid_tweets ,valid_labels)\n",
        "test_data_base  = tokenizer_obj_base.bert_tokenize_data(test_tweets,test_labels)\n",
        "\n",
        "train_loader_base,valid_loader_base=dialectUtils.create_bert_dataloader(train_data_base,\n",
        "                                                                        valid_data_base,\n",
        "                                                                        batch_size=32,\n",
        "                                                                        split_train= False)\n",
        "\n",
        "test_loader_base=dialectUtils.create_bert_dataloader(test_data_base,valid=None,batch_size=32,\n",
        "                                                split_train=False,test=True)\n",
        "BERTmodel_base=dialectUtils.get_model(preTrainedBertModel_base)\n",
        "dialectUtils.printModel_Parameters(BERTmodel_base)\n",
        "print(\"\\n\")\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "metadata": {
        "id": "Ka9YY8UOwMHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.train(train_loader_base,valid_loader_base,model=BERTmodel_base,epochs=5,learning_rate=2e-5,eps=1e-8,device =\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2l5vJ-2UFk",
        "outputId": "8c9e2db7-0943-43b8-f50d-ef733cc92389"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "  Batch   250  of  11,429.    Elapsed: 0:00:53.\n",
            "  Batch   500  of  11,429.    Elapsed: 0:01:46.\n",
            "  Batch   750  of  11,429.    Elapsed: 0:02:39.\n",
            "  Batch 1,000  of  11,429.    Elapsed: 0:03:32.\n",
            "  Batch 1,250  of  11,429.    Elapsed: 0:04:25.\n",
            "  Batch 1,500  of  11,429.    Elapsed: 0:05:18.\n",
            "  Batch 1,750  of  11,429.    Elapsed: 0:06:10.\n",
            "  Batch 2,000  of  11,429.    Elapsed: 0:07:03.\n",
            "  Batch 2,250  of  11,429.    Elapsed: 0:07:56.\n",
            "  Batch 2,500  of  11,429.    Elapsed: 0:08:49.\n",
            "  Batch 2,750  of  11,429.    Elapsed: 0:09:42.\n",
            "  Batch 3,000  of  11,429.    Elapsed: 0:10:35.\n",
            "  Batch 3,250  of  11,429.    Elapsed: 0:11:28.\n",
            "  Batch 3,500  of  11,429.    Elapsed: 0:12:21.\n",
            "  Batch 3,750  of  11,429.    Elapsed: 0:13:14.\n",
            "  Batch 4,000  of  11,429.    Elapsed: 0:14:07.\n",
            "  Batch 4,250  of  11,429.    Elapsed: 0:15:00.\n",
            "  Batch 4,500  of  11,429.    Elapsed: 0:15:52.\n",
            "  Batch 4,750  of  11,429.    Elapsed: 0:16:45.\n",
            "  Batch 5,000  of  11,429.    Elapsed: 0:17:38.\n",
            "  Batch 5,250  of  11,429.    Elapsed: 0:18:31.\n",
            "  Batch 5,500  of  11,429.    Elapsed: 0:19:24.\n",
            "  Batch 5,750  of  11,429.    Elapsed: 0:20:17.\n",
            "  Batch 6,000  of  11,429.    Elapsed: 0:21:10.\n",
            "  Batch 6,250  of  11,429.    Elapsed: 0:22:03.\n",
            "  Batch 6,500  of  11,429.    Elapsed: 0:22:56.\n",
            "  Batch 6,750  of  11,429.    Elapsed: 0:23:49.\n",
            "  Batch 7,000  of  11,429.    Elapsed: 0:24:42.\n",
            "  Batch 7,250  of  11,429.    Elapsed: 0:25:35.\n",
            "  Batch 7,500  of  11,429.    Elapsed: 0:26:28.\n",
            "  Batch 7,750  of  11,429.    Elapsed: 0:27:20.\n",
            "  Batch 8,000  of  11,429.    Elapsed: 0:28:13.\n",
            "  Batch 8,250  of  11,429.    Elapsed: 0:29:06.\n",
            "  Batch 8,500  of  11,429.    Elapsed: 0:29:59.\n",
            "  Batch 8,750  of  11,429.    Elapsed: 0:30:52.\n",
            "  Batch 9,000  of  11,429.    Elapsed: 0:31:45.\n",
            "  Batch 9,250  of  11,429.    Elapsed: 0:32:38.\n",
            "  Batch 9,500  of  11,429.    Elapsed: 0:33:31.\n",
            "  Batch 9,750  of  11,429.    Elapsed: 0:34:24.\n",
            "  Batch 10,000  of  11,429.    Elapsed: 0:35:17.\n",
            "  Batch 10,250  of  11,429.    Elapsed: 0:36:10.\n",
            "  Batch 10,500  of  11,429.    Elapsed: 0:37:03.\n",
            "  Batch 10,750  of  11,429.    Elapsed: 0:37:56.\n",
            "  Batch 11,000  of  11,429.    Elapsed: 0:38:49.\n",
            "  Batch 11,250  of  11,429.    Elapsed: 0:39:42.\n",
            "  Average training loss: 1.529779\n",
            "  Average training accuracy: 0.5168\n",
            "  Average training f1: 0.4792\n",
            "  Average training recall: 0.4636\n",
            "--------------------------------------------------\n",
            "  Average validation loss: 1.3469\n",
            "  Average validation accuracy: 0.5673\n",
            "  Average validation f1: 0.5355\n",
            "  Average validation recall: 0.5223\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "  Batch   250  of  11,429.    Elapsed: 0:00:53.\n",
            "  Batch   500  of  11,429.    Elapsed: 0:01:46.\n",
            "  Batch   750  of  11,429.    Elapsed: 0:02:39.\n",
            "  Batch 1,000  of  11,429.    Elapsed: 0:03:32.\n",
            "  Batch 1,250  of  11,429.    Elapsed: 0:04:25.\n",
            "  Batch 1,500  of  11,429.    Elapsed: 0:05:18.\n",
            "  Batch 1,750  of  11,429.    Elapsed: 0:06:11.\n",
            "  Batch 2,000  of  11,429.    Elapsed: 0:07:04.\n",
            "  Batch 2,250  of  11,429.    Elapsed: 0:07:57.\n",
            "  Batch 2,500  of  11,429.    Elapsed: 0:08:50.\n",
            "  Batch 2,750  of  11,429.    Elapsed: 0:09:42.\n",
            "  Batch 3,000  of  11,429.    Elapsed: 0:10:35.\n",
            "  Batch 3,250  of  11,429.    Elapsed: 0:11:28.\n",
            "  Batch 3,500  of  11,429.    Elapsed: 0:12:21.\n",
            "  Batch 3,750  of  11,429.    Elapsed: 0:13:14.\n",
            "  Batch 4,000  of  11,429.    Elapsed: 0:14:07.\n",
            "  Batch 4,250  of  11,429.    Elapsed: 0:15:00.\n",
            "  Batch 4,500  of  11,429.    Elapsed: 0:15:53.\n",
            "  Batch 4,750  of  11,429.    Elapsed: 0:16:46.\n",
            "  Batch 5,000  of  11,429.    Elapsed: 0:17:39.\n",
            "  Batch 5,250  of  11,429.    Elapsed: 0:18:31.\n",
            "  Batch 5,500  of  11,429.    Elapsed: 0:19:24.\n",
            "  Batch 5,750  of  11,429.    Elapsed: 0:20:17.\n",
            "  Batch 6,000  of  11,429.    Elapsed: 0:21:10.\n",
            "  Batch 6,250  of  11,429.    Elapsed: 0:22:03.\n",
            "  Batch 6,500  of  11,429.    Elapsed: 0:22:56.\n",
            "  Batch 6,750  of  11,429.    Elapsed: 0:23:49.\n",
            "  Batch 7,000  of  11,429.    Elapsed: 0:24:41.\n",
            "  Batch 7,250  of  11,429.    Elapsed: 0:25:34.\n",
            "  Batch 7,500  of  11,429.    Elapsed: 0:26:27.\n",
            "  Batch 7,750  of  11,429.    Elapsed: 0:27:20.\n",
            "  Batch 8,000  of  11,429.    Elapsed: 0:28:13.\n",
            "  Batch 8,250  of  11,429.    Elapsed: 0:29:06.\n",
            "  Batch 8,500  of  11,429.    Elapsed: 0:29:59.\n",
            "  Batch 8,750  of  11,429.    Elapsed: 0:30:52.\n",
            "  Batch 9,000  of  11,429.    Elapsed: 0:31:45.\n",
            "  Batch 9,250  of  11,429.    Elapsed: 0:32:37.\n",
            "  Batch 9,500  of  11,429.    Elapsed: 0:33:30.\n",
            "  Batch 9,750  of  11,429.    Elapsed: 0:34:23.\n",
            "  Batch 10,000  of  11,429.    Elapsed: 0:35:16.\n",
            "  Batch 10,250  of  11,429.    Elapsed: 0:36:09.\n",
            "  Batch 10,500  of  11,429.    Elapsed: 0:37:02.\n",
            "  Batch 10,750  of  11,429.    Elapsed: 0:37:55.\n",
            "  Batch 11,000  of  11,429.    Elapsed: 0:38:47.\n",
            "  Batch 11,250  of  11,429.    Elapsed: 0:39:40.\n",
            "  Average training loss: 1.230153\n",
            "  Average training accuracy: 0.6070\n",
            "  Average training f1: 0.5814\n",
            "  Average training recall: 0.5658\n",
            "--------------------------------------------------\n",
            "  Average validation loss: 1.2762\n",
            "  Average validation accuracy: 0.5931\n",
            "  Average validation f1: 0.5667\n",
            "  Average validation recall: 0.5505\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "  Batch   250  of  11,429.    Elapsed: 0:00:53.\n",
            "  Batch   500  of  11,429.    Elapsed: 0:01:46.\n",
            "  Batch   750  of  11,429.    Elapsed: 0:02:39.\n",
            "  Batch 1,000  of  11,429.    Elapsed: 0:03:32.\n",
            "  Batch 1,250  of  11,429.    Elapsed: 0:04:25.\n",
            "  Batch 1,500  of  11,429.    Elapsed: 0:05:18.\n",
            "  Batch 1,750  of  11,429.    Elapsed: 0:06:11.\n",
            "  Batch 2,000  of  11,429.    Elapsed: 0:07:04.\n",
            "  Batch 2,250  of  11,429.    Elapsed: 0:07:57.\n",
            "  Batch 2,500  of  11,429.    Elapsed: 0:08:50.\n",
            "  Batch 2,750  of  11,429.    Elapsed: 0:09:43.\n",
            "  Batch 3,000  of  11,429.    Elapsed: 0:10:35.\n",
            "  Batch 3,250  of  11,429.    Elapsed: 0:11:28.\n",
            "  Batch 3,500  of  11,429.    Elapsed: 0:12:21.\n",
            "  Batch 3,750  of  11,429.    Elapsed: 0:13:14.\n",
            "  Batch 4,000  of  11,429.    Elapsed: 0:14:07.\n",
            "  Batch 4,250  of  11,429.    Elapsed: 0:15:00.\n",
            "  Batch 4,500  of  11,429.    Elapsed: 0:15:53.\n",
            "  Batch 4,750  of  11,429.    Elapsed: 0:16:46.\n",
            "  Batch 5,000  of  11,429.    Elapsed: 0:17:39.\n",
            "  Batch 5,250  of  11,429.    Elapsed: 0:18:32.\n",
            "  Batch 5,500  of  11,429.    Elapsed: 0:19:25.\n",
            "  Batch 5,750  of  11,429.    Elapsed: 0:20:18.\n",
            "  Batch 6,000  of  11,429.    Elapsed: 0:21:11.\n",
            "  Batch 6,250  of  11,429.    Elapsed: 0:22:04.\n",
            "  Batch 6,500  of  11,429.    Elapsed: 0:22:57.\n",
            "  Batch 6,750  of  11,429.    Elapsed: 0:23:50.\n",
            "  Batch 7,000  of  11,429.    Elapsed: 0:24:42.\n",
            "  Batch 7,250  of  11,429.    Elapsed: 0:25:35.\n",
            "  Batch 7,500  of  11,429.    Elapsed: 0:26:28.\n",
            "  Batch 7,750  of  11,429.    Elapsed: 0:27:21.\n",
            "  Batch 8,000  of  11,429.    Elapsed: 0:28:14.\n",
            "  Batch 8,250  of  11,429.    Elapsed: 0:29:07.\n",
            "  Batch 8,500  of  11,429.    Elapsed: 0:30:00.\n",
            "  Batch 8,750  of  11,429.    Elapsed: 0:30:53.\n",
            "  Batch 9,000  of  11,429.    Elapsed: 0:31:46.\n",
            "  Batch 9,250  of  11,429.    Elapsed: 0:32:39.\n",
            "  Batch 9,500  of  11,429.    Elapsed: 0:33:32.\n",
            "  Batch 9,750  of  11,429.    Elapsed: 0:34:25.\n",
            "  Batch 10,000  of  11,429.    Elapsed: 0:35:18.\n",
            "  Batch 10,250  of  11,429.    Elapsed: 0:36:10.\n",
            "  Batch 10,500  of  11,429.    Elapsed: 0:37:03.\n",
            "  Batch 10,750  of  11,429.    Elapsed: 0:37:56.\n",
            "  Batch 11,000  of  11,429.    Elapsed: 0:38:49.\n",
            "  Batch 11,250  of  11,429.    Elapsed: 0:39:42.\n",
            "  Average training loss: 1.045974\n",
            "  Average training accuracy: 0.6653\n",
            "  Average training f1: 0.6449\n",
            "  Average training recall: 0.6304\n",
            "--------------------------------------------------\n",
            "  Average validation loss: 1.2736\n",
            "  Average validation accuracy: 0.6038\n",
            "  Average validation f1: 0.5797\n",
            "  Average validation recall: 0.5674\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "  Batch   250  of  11,429.    Elapsed: 0:00:53.\n",
            "  Batch   500  of  11,429.    Elapsed: 0:01:46.\n",
            "  Batch   750  of  11,429.    Elapsed: 0:02:39.\n",
            "  Batch 1,000  of  11,429.    Elapsed: 0:03:32.\n",
            "  Batch 1,250  of  11,429.    Elapsed: 0:04:25.\n",
            "  Batch 1,500  of  11,429.    Elapsed: 0:05:18.\n",
            "  Batch 1,750  of  11,429.    Elapsed: 0:06:10.\n",
            "  Batch 2,000  of  11,429.    Elapsed: 0:07:03.\n",
            "  Batch 2,250  of  11,429.    Elapsed: 0:07:56.\n",
            "  Batch 2,500  of  11,429.    Elapsed: 0:08:49.\n",
            "  Batch 2,750  of  11,429.    Elapsed: 0:09:42.\n",
            "  Batch 3,000  of  11,429.    Elapsed: 0:10:35.\n",
            "  Batch 3,250  of  11,429.    Elapsed: 0:11:28.\n",
            "  Batch 3,500  of  11,429.    Elapsed: 0:12:21.\n",
            "  Batch 3,750  of  11,429.    Elapsed: 0:13:14.\n",
            "  Batch 4,000  of  11,429.    Elapsed: 0:14:07.\n",
            "  Batch 4,250  of  11,429.    Elapsed: 0:15:00.\n",
            "  Batch 4,500  of  11,429.    Elapsed: 0:15:52.\n",
            "  Batch 4,750  of  11,429.    Elapsed: 0:16:45.\n",
            "  Batch 5,000  of  11,429.    Elapsed: 0:17:38.\n",
            "  Batch 5,250  of  11,429.    Elapsed: 0:18:31.\n",
            "  Batch 5,500  of  11,429.    Elapsed: 0:19:24.\n",
            "  Batch 5,750  of  11,429.    Elapsed: 0:20:17.\n",
            "  Batch 6,000  of  11,429.    Elapsed: 0:21:10.\n",
            "  Batch 6,250  of  11,429.    Elapsed: 0:22:03.\n",
            "  Batch 6,500  of  11,429.    Elapsed: 0:22:56.\n",
            "  Batch 6,750  of  11,429.    Elapsed: 0:23:49.\n",
            "  Batch 7,000  of  11,429.    Elapsed: 0:24:41.\n",
            "  Batch 7,250  of  11,429.    Elapsed: 0:25:34.\n",
            "  Batch 7,500  of  11,429.    Elapsed: 0:26:27.\n",
            "  Batch 7,750  of  11,429.    Elapsed: 0:27:20.\n",
            "  Batch 8,000  of  11,429.    Elapsed: 0:28:13.\n",
            "  Batch 8,250  of  11,429.    Elapsed: 0:29:06.\n",
            "  Batch 8,500  of  11,429.    Elapsed: 0:29:59.\n",
            "  Batch 8,750  of  11,429.    Elapsed: 0:30:52.\n",
            "  Batch 9,000  of  11,429.    Elapsed: 0:31:45.\n",
            "  Batch 9,250  of  11,429.    Elapsed: 0:32:38.\n",
            "  Batch 9,500  of  11,429.    Elapsed: 0:33:31.\n",
            "  Batch 9,750  of  11,429.    Elapsed: 0:34:23.\n",
            "  Batch 10,000  of  11,429.    Elapsed: 0:35:16.\n",
            "  Batch 10,250  of  11,429.    Elapsed: 0:36:09.\n",
            "  Batch 10,500  of  11,429.    Elapsed: 0:37:02.\n",
            "  Batch 10,750  of  11,429.    Elapsed: 0:37:55.\n",
            "  Batch 11,000  of  11,429.    Elapsed: 0:38:48.\n",
            "  Batch 11,250  of  11,429.    Elapsed: 0:39:41.\n",
            "  Average training loss: 0.900346\n",
            "  Average training accuracy: 0.7113\n",
            "  Average training f1: 0.6940\n",
            "  Average training recall: 0.6811\n",
            "--------------------------------------------------\n",
            "  Average validation loss: 1.3157\n",
            "  Average validation accuracy: 0.6030\n",
            "  Average validation f1: 0.5814\n",
            "  Average validation recall: 0.5696\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "  Batch   250  of  11,429.    Elapsed: 0:00:53.\n",
            "  Batch   500  of  11,429.    Elapsed: 0:01:46.\n",
            "  Batch   750  of  11,429.    Elapsed: 0:02:39.\n",
            "  Batch 1,000  of  11,429.    Elapsed: 0:03:32.\n",
            "  Batch 1,250  of  11,429.    Elapsed: 0:04:25.\n",
            "  Batch 1,500  of  11,429.    Elapsed: 0:05:18.\n",
            "  Batch 1,750  of  11,429.    Elapsed: 0:06:10.\n",
            "  Batch 2,000  of  11,429.    Elapsed: 0:07:03.\n",
            "  Batch 2,250  of  11,429.    Elapsed: 0:07:56.\n",
            "  Batch 2,500  of  11,429.    Elapsed: 0:08:49.\n",
            "  Batch 2,750  of  11,429.    Elapsed: 0:09:42.\n",
            "  Batch 3,000  of  11,429.    Elapsed: 0:10:35.\n",
            "  Batch 3,250  of  11,429.    Elapsed: 0:11:28.\n",
            "  Batch 3,500  of  11,429.    Elapsed: 0:12:21.\n",
            "  Batch 3,750  of  11,429.    Elapsed: 0:13:14.\n",
            "  Batch 4,000  of  11,429.    Elapsed: 0:14:07.\n",
            "  Batch 4,250  of  11,429.    Elapsed: 0:15:00.\n",
            "  Batch 4,500  of  11,429.    Elapsed: 0:15:53.\n",
            "  Batch 4,750  of  11,429.    Elapsed: 0:16:45.\n",
            "  Batch 5,000  of  11,429.    Elapsed: 0:17:38.\n",
            "  Batch 5,250  of  11,429.    Elapsed: 0:18:31.\n",
            "  Batch 5,500  of  11,429.    Elapsed: 0:19:24.\n",
            "  Batch 5,750  of  11,429.    Elapsed: 0:20:17.\n",
            "  Batch 6,000  of  11,429.    Elapsed: 0:21:10.\n",
            "  Batch 6,250  of  11,429.    Elapsed: 0:22:03.\n",
            "  Batch 6,500  of  11,429.    Elapsed: 0:22:56.\n",
            "  Batch 6,750  of  11,429.    Elapsed: 0:23:49.\n",
            "  Batch 7,000  of  11,429.    Elapsed: 0:24:42.\n",
            "  Batch 7,250  of  11,429.    Elapsed: 0:25:35.\n",
            "  Batch 7,500  of  11,429.    Elapsed: 0:26:28.\n",
            "  Batch 7,750  of  11,429.    Elapsed: 0:27:20.\n",
            "  Batch 8,000  of  11,429.    Elapsed: 0:28:13.\n",
            "  Batch 8,250  of  11,429.    Elapsed: 0:29:06.\n",
            "  Batch 8,500  of  11,429.    Elapsed: 0:29:59.\n",
            "  Batch 8,750  of  11,429.    Elapsed: 0:30:52.\n",
            "  Batch 9,000  of  11,429.    Elapsed: 0:31:45.\n",
            "  Batch 9,250  of  11,429.    Elapsed: 0:32:38.\n",
            "  Batch 9,500  of  11,429.    Elapsed: 0:33:31.\n",
            "  Batch 9,750  of  11,429.    Elapsed: 0:34:24.\n",
            "  Batch 10,000  of  11,429.    Elapsed: 0:35:17.\n",
            "  Batch 10,250  of  11,429.    Elapsed: 0:36:09.\n",
            "  Batch 10,500  of  11,429.    Elapsed: 0:37:02.\n",
            "  Batch 10,750  of  11,429.    Elapsed: 0:37:55.\n",
            "  Batch 11,000  of  11,429.    Elapsed: 0:38:48.\n",
            "  Batch 11,250  of  11,429.    Elapsed: 0:39:41.\n",
            "  Average training loss: 0.799636\n",
            "  Average training accuracy: 0.7449\n",
            "  Average training f1: 0.7295\n",
            "  Average training recall: 0.7177\n",
            "--------------------------------------------------\n",
            "  Average validation loss: 1.3447\n",
            "  Average validation accuracy: 0.6037\n",
            "  Average validation f1: 0.5812\n",
            "  Average validation recall: 0.5704\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on Test"
      ],
      "metadata": {
        "id": "sSb5DWUqjuUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_base,actual = dialectUtils.Batchpredict(BERTmodel_base,test_loader_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpiKNH6XohS3",
        "outputId": "61e426be-0d90-4080-fccc-e3ceee9c7588"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.get_report(pred_base,actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYrWmjSQqzb7",
        "outputId": "b42e38f2-7275-4413-ad02-94ccc13c5c81"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.78      0.88      0.83      5756\n",
            "          PL       0.55      0.57      0.56      4368\n",
            "          KW       0.57      0.60      0.58      4200\n",
            "          LY       0.76      0.74      0.75      3647\n",
            "          QA       0.53      0.54      0.54      3105\n",
            "          JO       0.46      0.42      0.44      2784\n",
            "          LB       0.72      0.68      0.70      2757\n",
            "          SA       0.48      0.56      0.51      2678\n",
            "          AE       0.48      0.50      0.49      2620\n",
            "          BH       0.42      0.41      0.41      2612\n",
            "          OM       0.49      0.49      0.49      1904\n",
            "          SY       0.49      0.43      0.46      1621\n",
            "          DZ       0.64      0.62      0.63      1614\n",
            "          IQ       0.67      0.61      0.64      1548\n",
            "          SD       0.75      0.66      0.70      1438\n",
            "          MA       0.79      0.64      0.71      1153\n",
            "          YE       0.40      0.31      0.35       988\n",
            "          TN       0.71      0.51      0.60       923\n",
            "\n",
            "    accuracy                           0.60     45716\n",
            "   macro avg       0.59      0.57      0.58     45716\n",
            "weighted avg       0.60      0.60      0.60     45716\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Base Model"
      ],
      "metadata": {
        "id": "CfV97AZayvk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Aim_NLP_Task/BERT_Fine_Tuning_dialect_base_0.60'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = BERTmodel_base.module if hasattr(BERTmodel_base, 'module') else BERTmodel_base  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer_obj_base.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "metadata": {
        "id": "0nNBhZG6tZqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Aim_NLP_Task/Models_Weight/model_base_0.60.pth\"\n",
        "torch.save(BERTmodel_base.cpu().state_dict(), path) # saving model\n",
        "BERTmodel_base.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPby4mzTtfJA",
        "outputId": "c3233086-ce05-406e-8fa2-d19b140857a9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pretrained Model"
      ],
      "metadata": {
        "id": "JurT1OmjzQKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir_base=\"/content/drive/MyDrive/Aim_NLP_Task/BERT_Fine_Tuning_dialect_base_0.60\"\n",
        "test_tweets,test_labels = dialectUtils.read_csv(\"../Data/preProcessedTweets_testF.csv\",\n",
        "                                                  \"text_preprocessed\",\"label\")"
      ],
      "metadata": {
        "id": "QEn48-iczQKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_class_base = BertTokenizer.from_pretrained(output_dir_base)\n",
        "load_BERTmodel_base  = BertForSequenceClassification.from_pretrained(output_dir_base)"
      ],
      "metadata": {
        "id": "JHtafPJJzQKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_BERTmodel_base.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0f1fb1-ce13-41c5-ad58-29b7f84433f2",
        "id": "-_Tq15tozQKU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_base  = tokenizer_class_base.bert_tokenize_data(test_tweets,test_labels)\n",
        "test_loader_base=dialectUtils.create_bert_dataloader(test_data_base,valid=None,batch_size=32,\n",
        "                                                split_train=False,test=True)"
      ],
      "metadata": {
        "id": "jU6F04Npz2TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_base,actual = dialectUtils.Batchpredict(load_BERTmodel_base,test_loader_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd16942-8ef2-486f-9108-972e30da865a",
        "id": "toQbof72zQKV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.get_report(pred_base,actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b104b4cb-d366-49f3-e545-490d72afdad0",
        "id": "PwTneAhgzQKW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.86      0.92      0.89      5756\n",
            "          PL       0.58      0.78      0.66      4368\n",
            "          KW       0.62      0.79      0.69      4200\n",
            "          LY       0.78      0.87      0.83      3647\n",
            "          QA       0.74      0.55      0.63      3105\n",
            "          JO       0.63      0.49      0.55      2784\n",
            "          LB       0.85      0.77      0.81      2757\n",
            "          SA       0.64      0.68      0.66      2678\n",
            "          AE       0.65      0.61      0.63      2620\n",
            "          BH       0.53      0.55      0.54      2612\n",
            "          OM       0.64      0.61      0.63      1904\n",
            "          SY       0.72      0.55      0.62      1621\n",
            "          DZ       0.82      0.66      0.73      1614\n",
            "          IQ       0.87      0.70      0.78      1548\n",
            "          SD       0.92      0.74      0.82      1438\n",
            "          MA       0.91      0.71      0.80      1153\n",
            "          YE       0.57      0.47      0.51       988\n",
            "          TN       0.73      0.65      0.69       923\n",
            "\n",
            "    accuracy                           0.71     45716\n",
            "   macro avg       0.73      0.67      0.69     45716\n",
            "weighted avg       0.72      0.71      0.71     45716\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________"
      ],
      "metadata": {
        "id": "qJk1pAK62gEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert `Large` AraBert"
      ],
      "metadata": {
        "id": "iPZAAQmZx_L8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "J2qhxyM-0Wkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preTrainedBertModel_large=\"aubmindlab/bert-large-arabertv02-twitter\"\n",
        "\n",
        "tokenizer_large= AutoTokenizer.from_pretrained(preTrainedBertModel_large)\n",
        "tokenizer_obj_large = dialectUtils.Tokenizer(tokenizer_large)\n",
        "\n",
        "\n",
        "train_data_large = tokenizer_obj_large.bert_tokenize_data(train_tweets,train_labels)\n",
        "valid_data_large = tokenizer_obj_large.bert_tokenize_data(valid_tweets ,valid_labels)\n",
        "test_data_large  = tokenizer_obj_large.bert_tokenize_data(test_tweets,test_labels)\n",
        "\n",
        "train_loader_large,valid_loader_large=dialectUtils.create_bert_dataloader(train_data_large,\n",
        "                                                                        valid_data_large,\n",
        "                                                                        batch_size=64,\n",
        "                                                                        split_train= False)\n",
        "\n",
        "test_loader_large=dialectUtils.create_bert_dataloader(test_data_large,valid=None,batch_size=64,\n",
        "                                                split_train=False,test=True)\n",
        "\n",
        "BERTmodel_large=dialectUtils.get_model(preTrainedBertModel_large)\n",
        "dialectUtils.printModel_Parameters(BERTmodel_large)\n",
        "print(\"\\n\")\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "metadata": {
        "id": "PPxX6HjH0VYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.train(train_loader_large,valid_loader_large,model=BERTmodel_large,epochs=5,learning_rate=2e-5,eps=1e-8,device =\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68745cc9-7906-4ecd-8f11-60d50b4e120c",
        "id": "AEy7uD-k3BN1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "  Batch    40  of  5,728.    Elapsed: 0:00:52.\n",
            "  Batch    80  of  5,728.    Elapsed: 0:01:43.\n",
            "  Batch   120  of  5,728.    Elapsed: 0:02:34.\n",
            "  Batch   160  of  5,728.    Elapsed: 0:03:25.\n",
            "  Batch   200  of  5,728.    Elapsed: 0:04:16.\n",
            "  Batch   240  of  5,728.    Elapsed: 0:05:07.\n",
            "  Batch   280  of  5,728.    Elapsed: 0:05:58.\n",
            "  Batch   320  of  5,728.    Elapsed: 0:06:49.\n",
            "  Batch   360  of  5,728.    Elapsed: 0:07:40.\n",
            "  Batch   400  of  5,728.    Elapsed: 0:08:30.\n",
            "  Batch   440  of  5,728.    Elapsed: 0:09:21.\n",
            "  Batch   480  of  5,728.    Elapsed: 0:10:12.\n",
            "  Batch   520  of  5,728.    Elapsed: 0:11:03.\n",
            "  Batch   560  of  5,728.    Elapsed: 0:11:54.\n",
            "  Batch   600  of  5,728.    Elapsed: 0:12:45.\n",
            "  Batch   640  of  5,728.    Elapsed: 0:13:36.\n",
            "  Batch   680  of  5,728.    Elapsed: 0:14:26.\n",
            "  Batch   720  of  5,728.    Elapsed: 0:15:17.\n",
            "  Batch   760  of  5,728.    Elapsed: 0:16:08.\n",
            "  Batch   800  of  5,728.    Elapsed: 0:16:59.\n",
            "  Batch   840  of  5,728.    Elapsed: 0:17:50.\n",
            "  Batch   880  of  5,728.    Elapsed: 0:18:41.\n",
            "  Batch   920  of  5,728.    Elapsed: 0:19:32.\n",
            "  Batch   960  of  5,728.    Elapsed: 0:20:23.\n",
            "  Batch 1,000  of  5,728.    Elapsed: 0:21:14.\n",
            "  Batch 1,040  of  5,728.    Elapsed: 0:22:05.\n",
            "  Batch 1,080  of  5,728.    Elapsed: 0:22:56.\n",
            "  Batch 1,120  of  5,728.    Elapsed: 0:23:47.\n",
            "  Batch 1,160  of  5,728.    Elapsed: 0:24:37.\n",
            "  Batch 1,200  of  5,728.    Elapsed: 0:25:28.\n",
            "  Batch 1,240  of  5,728.    Elapsed: 0:26:19.\n",
            "  Batch 1,280  of  5,728.    Elapsed: 0:27:10.\n",
            "  Batch 1,320  of  5,728.    Elapsed: 0:28:01.\n",
            "  Batch 1,360  of  5,728.    Elapsed: 0:28:52.\n",
            "  Batch 1,400  of  5,728.    Elapsed: 0:29:43.\n",
            "  Batch 1,440  of  5,728.    Elapsed: 0:30:34.\n",
            "  Batch 1,480  of  5,728.    Elapsed: 0:31:25.\n",
            "  Batch 1,520  of  5,728.    Elapsed: 0:32:16.\n",
            "  Batch 1,560  of  5,728.    Elapsed: 0:33:07.\n",
            "  Batch 1,600  of  5,728.    Elapsed: 0:33:58.\n",
            "  Batch 1,640  of  5,728.    Elapsed: 0:34:48.\n",
            "  Batch 1,680  of  5,728.    Elapsed: 0:35:39.\n",
            "  Batch 1,720  of  5,728.    Elapsed: 0:36:30.\n",
            "  Batch 1,760  of  5,728.    Elapsed: 0:37:21.\n",
            "  Batch 1,800  of  5,728.    Elapsed: 0:38:12.\n",
            "  Batch 1,840  of  5,728.    Elapsed: 0:39:03.\n",
            "  Batch 1,880  of  5,728.    Elapsed: 0:39:54.\n",
            "  Batch 1,920  of  5,728.    Elapsed: 0:40:44.\n",
            "  Batch 1,960  of  5,728.    Elapsed: 0:41:35.\n",
            "  Batch 2,000  of  5,728.    Elapsed: 0:42:26.\n",
            "  Batch 2,040  of  5,728.    Elapsed: 0:43:17.\n",
            "  Batch 2,080  of  5,728.    Elapsed: 0:44:07.\n",
            "  Batch 2,120  of  5,728.    Elapsed: 0:44:58.\n",
            "  Batch 2,160  of  5,728.    Elapsed: 0:45:49.\n",
            "  Batch 2,200  of  5,728.    Elapsed: 0:46:40.\n",
            "  Batch 2,240  of  5,728.    Elapsed: 0:47:30.\n",
            "  Batch 2,280  of  5,728.    Elapsed: 0:48:22.\n",
            "  Batch 2,320  of  5,728.    Elapsed: 0:49:12.\n",
            "  Batch 2,360  of  5,728.    Elapsed: 0:50:03.\n",
            "  Batch 2,400  of  5,728.    Elapsed: 0:50:55.\n",
            "  Batch 2,440  of  5,728.    Elapsed: 0:51:45.\n",
            "  Batch 2,480  of  5,728.    Elapsed: 0:52:36.\n",
            "  Batch 2,520  of  5,728.    Elapsed: 0:53:28.\n",
            "  Batch 2,560  of  5,728.    Elapsed: 0:54:18.\n",
            "  Batch 2,600  of  5,728.    Elapsed: 0:55:09.\n",
            "  Batch 2,640  of  5,728.    Elapsed: 0:56:00.\n",
            "  Batch 2,680  of  5,728.    Elapsed: 0:56:51.\n",
            "  Batch 2,720  of  5,728.    Elapsed: 0:57:42.\n",
            "  Batch 2,760  of  5,728.    Elapsed: 0:58:33.\n",
            "  Batch 2,800  of  5,728.    Elapsed: 0:59:24.\n",
            "  Batch 2,840  of  5,728.    Elapsed: 1:00:15.\n",
            "  Batch 2,880  of  5,728.    Elapsed: 1:01:06.\n",
            "  Batch 2,920  of  5,728.    Elapsed: 1:01:57.\n",
            "  Batch 2,960  of  5,728.    Elapsed: 1:02:48.\n",
            "  Batch 3,000  of  5,728.    Elapsed: 1:03:38.\n",
            "  Batch 3,040  of  5,728.    Elapsed: 1:04:29.\n",
            "  Batch 3,080  of  5,728.    Elapsed: 1:05:20.\n",
            "  Batch 3,120  of  5,728.    Elapsed: 1:06:11.\n",
            "  Batch 3,160  of  5,728.    Elapsed: 1:07:02.\n",
            "  Batch 3,200  of  5,728.    Elapsed: 1:07:53.\n",
            "  Batch 3,240  of  5,728.    Elapsed: 1:08:44.\n",
            "  Batch 3,280  of  5,728.    Elapsed: 1:09:35.\n",
            "  Batch 3,320  of  5,728.    Elapsed: 1:10:26.\n",
            "  Batch 3,360  of  5,728.    Elapsed: 1:11:17.\n",
            "  Batch 3,400  of  5,728.    Elapsed: 1:12:08.\n",
            "  Batch 3,440  of  5,728.    Elapsed: 1:12:59.\n",
            "  Batch 3,480  of  5,728.    Elapsed: 1:13:50.\n",
            "  Batch 3,520  of  5,728.    Elapsed: 1:14:41.\n",
            "  Batch 3,560  of  5,728.    Elapsed: 1:15:32.\n",
            "  Batch 3,600  of  5,728.    Elapsed: 1:16:23.\n",
            "  Batch 3,640  of  5,728.    Elapsed: 1:17:14.\n",
            "  Batch 3,680  of  5,728.    Elapsed: 1:18:05.\n",
            "  Batch 3,720  of  5,728.    Elapsed: 1:18:55.\n",
            "  Batch 3,760  of  5,728.    Elapsed: 1:19:47.\n",
            "  Batch 3,800  of  5,728.    Elapsed: 1:20:38.\n",
            "  Batch 3,840  of  5,728.    Elapsed: 1:21:29.\n",
            "  Batch 3,880  of  5,728.    Elapsed: 1:22:20.\n",
            "  Batch 3,920  of  5,728.    Elapsed: 1:23:11.\n",
            "  Batch 3,960  of  5,728.    Elapsed: 1:24:02.\n",
            "  Batch 4,000  of  5,728.    Elapsed: 1:24:52.\n",
            "  Batch 4,040  of  5,728.    Elapsed: 1:25:43.\n",
            "  Batch 4,080  of  5,728.    Elapsed: 1:26:34.\n",
            "  Batch 4,120  of  5,728.    Elapsed: 1:27:25.\n",
            "  Batch 4,160  of  5,728.    Elapsed: 1:28:16.\n",
            "  Batch 4,200  of  5,728.    Elapsed: 1:29:06.\n",
            "  Batch 4,240  of  5,728.    Elapsed: 1:29:57.\n",
            "  Batch 4,280  of  5,728.    Elapsed: 1:30:48.\n",
            "  Batch 4,320  of  5,728.    Elapsed: 1:31:39.\n",
            "  Batch 4,360  of  5,728.    Elapsed: 1:32:30.\n",
            "  Batch 4,400  of  5,728.    Elapsed: 1:33:21.\n",
            "  Batch 4,440  of  5,728.    Elapsed: 1:34:12.\n",
            "  Batch 4,480  of  5,728.    Elapsed: 1:35:03.\n",
            "  Batch 4,520  of  5,728.    Elapsed: 1:35:54.\n",
            "  Batch 4,560  of  5,728.    Elapsed: 1:36:45.\n",
            "  Batch 4,600  of  5,728.    Elapsed: 1:37:35.\n",
            "  Batch 4,640  of  5,728.    Elapsed: 1:38:26.\n",
            "  Batch 4,680  of  5,728.    Elapsed: 1:39:18.\n",
            "  Batch 4,720  of  5,728.    Elapsed: 1:40:08.\n",
            "  Batch 4,760  of  5,728.    Elapsed: 1:40:59.\n",
            "  Batch 4,800  of  5,728.    Elapsed: 1:41:50.\n",
            "  Batch 4,840  of  5,728.    Elapsed: 1:42:41.\n",
            "  Batch 4,880  of  5,728.    Elapsed: 1:43:31.\n",
            "  Batch 4,920  of  5,728.    Elapsed: 1:44:22.\n",
            "  Batch 4,960  of  5,728.    Elapsed: 1:45:13.\n",
            "  Batch 5,000  of  5,728.    Elapsed: 1:46:04.\n",
            "  Batch 5,040  of  5,728.    Elapsed: 1:46:55.\n",
            "  Batch 5,080  of  5,728.    Elapsed: 1:47:45.\n",
            "  Batch 5,120  of  5,728.    Elapsed: 1:48:35.\n",
            "  Batch 5,160  of  5,728.    Elapsed: 1:49:26.\n",
            "  Batch 5,200  of  5,728.    Elapsed: 1:50:17.\n",
            "  Batch 5,240  of  5,728.    Elapsed: 1:51:08.\n",
            "  Batch 5,280  of  5,728.    Elapsed: 1:51:59.\n",
            "  Batch 5,320  of  5,728.    Elapsed: 1:52:50.\n",
            "  Batch 5,360  of  5,728.    Elapsed: 1:53:40.\n",
            "  Batch 5,400  of  5,728.    Elapsed: 1:54:32.\n",
            "  Batch 5,440  of  5,728.    Elapsed: 1:55:22.\n",
            "  Batch 5,480  of  5,728.    Elapsed: 1:56:13.\n",
            "  Batch 5,520  of  5,728.    Elapsed: 1:57:04.\n",
            "  Batch 5,560  of  5,728.    Elapsed: 1:57:55.\n",
            "  Batch 5,600  of  5,728.    Elapsed: 1:58:46.\n",
            "  Batch 5,640  of  5,728.    Elapsed: 1:59:37.\n",
            "  Batch 5,680  of  5,728.    Elapsed: 2:00:28.\n",
            "  Batch 5,720  of  5,728.    Elapsed: 2:01:19.\n",
            "  Average training loss: 1.524763\n",
            "  Average training accuracy: 0.5173\n",
            "  Average training f1: 0.4799\n",
            "  Average training recall: 0.4639\n",
            "--------------------------------------------------\n",
            "  Batch    40  of    716.    Elapsed: 0:00:49.\n",
            "  Batch    80  of    716.    Elapsed: 0:01:37.\n",
            "  Batch   120  of    716.    Elapsed: 0:02:26.\n",
            "  Batch   160  of    716.    Elapsed: 0:03:14.\n",
            "  Batch   200  of    716.    Elapsed: 0:04:03.\n",
            "  Batch   240  of    716.    Elapsed: 0:04:52.\n",
            "  Batch   280  of    716.    Elapsed: 0:05:40.\n",
            "  Batch   320  of    716.    Elapsed: 0:06:28.\n",
            "  Batch   360  of    716.    Elapsed: 0:07:17.\n",
            "  Batch   400  of    716.    Elapsed: 0:08:05.\n",
            "  Batch   440  of    716.    Elapsed: 0:08:54.\n",
            "  Batch   480  of    716.    Elapsed: 0:09:42.\n",
            "  Batch   520  of    716.    Elapsed: 0:10:30.\n",
            "  Batch   560  of    716.    Elapsed: 0:11:18.\n",
            "  Batch   600  of    716.    Elapsed: 0:12:05.\n",
            "  Batch   640  of    716.    Elapsed: 0:12:53.\n",
            "  Batch   680  of    716.    Elapsed: 0:13:41.\n",
            "  Average validation loss: 1.3494\n",
            "  Average validation accuracy: 0.5674\n",
            "  Average validation f1: 0.5336\n",
            "  Average validation recall: 0.5164\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "  Batch    40  of  5,728.    Elapsed: 0:00:51.\n",
            "  Batch    80  of  5,728.    Elapsed: 0:01:42.\n",
            "  Batch   120  of  5,728.    Elapsed: 0:02:33.\n",
            "  Batch   160  of  5,728.    Elapsed: 0:03:24.\n",
            "  Batch   200  of  5,728.    Elapsed: 0:04:15.\n",
            "  Batch   240  of  5,728.    Elapsed: 0:05:06.\n",
            "  Batch   280  of  5,728.    Elapsed: 0:05:57.\n",
            "  Batch   320  of  5,728.    Elapsed: 0:06:48.\n",
            "  Batch   360  of  5,728.    Elapsed: 0:07:39.\n",
            "  Batch   400  of  5,728.    Elapsed: 0:08:30.\n",
            "  Batch   440  of  5,728.    Elapsed: 0:09:21.\n",
            "  Batch   480  of  5,728.    Elapsed: 0:10:12.\n",
            "  Batch   520  of  5,728.    Elapsed: 0:11:03.\n",
            "  Batch   560  of  5,728.    Elapsed: 0:11:53.\n",
            "  Batch   600  of  5,728.    Elapsed: 0:12:44.\n",
            "  Batch   640  of  5,728.    Elapsed: 0:13:35.\n",
            "  Batch   680  of  5,728.    Elapsed: 0:14:26.\n",
            "  Batch   720  of  5,728.    Elapsed: 0:15:17.\n",
            "  Batch   760  of  5,728.    Elapsed: 0:16:08.\n",
            "  Batch   800  of  5,728.    Elapsed: 0:16:59.\n",
            "  Batch   840  of  5,728.    Elapsed: 0:17:49.\n",
            "  Batch   880  of  5,728.    Elapsed: 0:18:40.\n",
            "  Batch   920  of  5,728.    Elapsed: 0:19:31.\n",
            "  Batch   960  of  5,728.    Elapsed: 0:20:22.\n",
            "  Batch 1,000  of  5,728.    Elapsed: 0:21:13.\n",
            "  Batch 1,040  of  5,728.    Elapsed: 0:22:04.\n",
            "  Batch 1,080  of  5,728.    Elapsed: 0:22:55.\n",
            "  Batch 1,120  of  5,728.    Elapsed: 0:23:46.\n",
            "  Batch 1,160  of  5,728.    Elapsed: 0:24:36.\n",
            "  Batch 1,200  of  5,728.    Elapsed: 0:25:27.\n",
            "  Batch 1,240  of  5,728.    Elapsed: 0:26:18.\n",
            "  Batch 1,280  of  5,728.    Elapsed: 0:27:09.\n",
            "  Batch 1,320  of  5,728.    Elapsed: 0:28:00.\n",
            "  Batch 1,360  of  5,728.    Elapsed: 0:28:51.\n",
            "  Batch 1,400  of  5,728.    Elapsed: 0:29:42.\n",
            "  Batch 1,440  of  5,728.    Elapsed: 0:30:33.\n",
            "  Batch 1,480  of  5,728.    Elapsed: 0:31:24.\n",
            "  Batch 1,520  of  5,728.    Elapsed: 0:32:15.\n",
            "  Batch 1,560  of  5,728.    Elapsed: 0:33:06.\n",
            "  Batch 1,600  of  5,728.    Elapsed: 0:33:57.\n",
            "  Batch 1,640  of  5,728.    Elapsed: 0:34:48.\n",
            "  Batch 1,680  of  5,728.    Elapsed: 0:35:39.\n",
            "  Batch 1,720  of  5,728.    Elapsed: 0:36:31.\n",
            "  Batch 1,760  of  5,728.    Elapsed: 0:37:22.\n",
            "  Batch 1,800  of  5,728.    Elapsed: 0:38:13.\n",
            "  Batch 1,840  of  5,728.    Elapsed: 0:39:04.\n",
            "  Batch 1,880  of  5,728.    Elapsed: 0:39:55.\n",
            "  Batch 1,920  of  5,728.    Elapsed: 0:40:46.\n",
            "  Batch 1,960  of  5,728.    Elapsed: 0:41:37.\n",
            "  Batch 2,000  of  5,728.    Elapsed: 0:42:28.\n",
            "  Batch 2,040  of  5,728.    Elapsed: 0:43:19.\n",
            "  Batch 2,080  of  5,728.    Elapsed: 0:44:10.\n",
            "  Batch 2,120  of  5,728.    Elapsed: 0:45:01.\n",
            "  Batch 2,160  of  5,728.    Elapsed: 0:45:52.\n",
            "  Batch 2,200  of  5,728.    Elapsed: 0:46:43.\n",
            "  Batch 2,240  of  5,728.    Elapsed: 0:47:34.\n",
            "  Batch 2,280  of  5,728.    Elapsed: 0:48:25.\n",
            "  Batch 2,320  of  5,728.    Elapsed: 0:49:16.\n",
            "  Batch 2,360  of  5,728.    Elapsed: 0:50:07.\n",
            "  Batch 2,400  of  5,728.    Elapsed: 0:50:58.\n",
            "  Batch 2,440  of  5,728.    Elapsed: 0:51:49.\n",
            "  Batch 2,480  of  5,728.    Elapsed: 0:52:40.\n",
            "  Batch 2,520  of  5,728.    Elapsed: 0:53:31.\n",
            "  Batch 2,560  of  5,728.    Elapsed: 0:54:22.\n",
            "  Batch 2,600  of  5,728.    Elapsed: 0:55:13.\n",
            "  Batch 2,640  of  5,728.    Elapsed: 0:56:04.\n",
            "  Batch 2,680  of  5,728.    Elapsed: 0:56:55.\n",
            "  Batch 2,720  of  5,728.    Elapsed: 0:57:46.\n",
            "  Batch 2,760  of  5,728.    Elapsed: 0:58:37.\n",
            "  Batch 2,800  of  5,728.    Elapsed: 0:59:28.\n",
            "  Batch 2,840  of  5,728.    Elapsed: 1:00:19.\n",
            "  Batch 2,880  of  5,728.    Elapsed: 1:01:10.\n",
            "  Batch 2,920  of  5,728.    Elapsed: 1:02:01.\n",
            "  Batch 2,960  of  5,728.    Elapsed: 1:02:52.\n",
            "  Batch 3,000  of  5,728.    Elapsed: 1:03:43.\n",
            "  Batch 3,040  of  5,728.    Elapsed: 1:04:34.\n",
            "  Batch 3,080  of  5,728.    Elapsed: 1:05:25.\n",
            "  Batch 3,120  of  5,728.    Elapsed: 1:06:16.\n",
            "  Batch 3,160  of  5,728.    Elapsed: 1:07:07.\n",
            "  Batch 3,200  of  5,728.    Elapsed: 1:07:59.\n",
            "  Batch 3,240  of  5,728.    Elapsed: 1:08:50.\n",
            "  Batch 3,280  of  5,728.    Elapsed: 1:09:41.\n",
            "  Batch 3,320  of  5,728.    Elapsed: 1:10:32.\n",
            "  Batch 3,360  of  5,728.    Elapsed: 1:11:23.\n",
            "  Batch 3,400  of  5,728.    Elapsed: 1:12:14.\n",
            "  Batch 3,440  of  5,728.    Elapsed: 1:13:05.\n",
            "  Batch 3,480  of  5,728.    Elapsed: 1:13:56.\n",
            "  Batch 3,520  of  5,728.    Elapsed: 1:14:47.\n",
            "  Batch 3,560  of  5,728.    Elapsed: 1:15:38.\n",
            "  Batch 3,600  of  5,728.    Elapsed: 1:16:29.\n",
            "  Batch 3,640  of  5,728.    Elapsed: 1:17:21.\n",
            "  Batch 3,680  of  5,728.    Elapsed: 1:18:11.\n",
            "  Batch 3,720  of  5,728.    Elapsed: 1:19:03.\n",
            "  Batch 3,760  of  5,728.    Elapsed: 1:19:54.\n",
            "  Batch 3,800  of  5,728.    Elapsed: 1:20:45.\n",
            "  Batch 3,840  of  5,728.    Elapsed: 1:21:36.\n",
            "  Batch 3,880  of  5,728.    Elapsed: 1:22:27.\n",
            "  Batch 3,920  of  5,728.    Elapsed: 1:23:18.\n",
            "  Batch 3,960  of  5,728.    Elapsed: 1:24:09.\n",
            "  Batch 4,000  of  5,728.    Elapsed: 1:25:00.\n",
            "  Batch 4,040  of  5,728.    Elapsed: 1:25:51.\n",
            "  Batch 4,080  of  5,728.    Elapsed: 1:26:42.\n",
            "  Batch 4,120  of  5,728.    Elapsed: 1:27:33.\n",
            "  Batch 4,160  of  5,728.    Elapsed: 1:28:24.\n",
            "  Batch 4,200  of  5,728.    Elapsed: 1:29:15.\n",
            "  Batch 4,240  of  5,728.    Elapsed: 1:30:06.\n",
            "  Batch 4,280  of  5,728.    Elapsed: 1:30:58.\n",
            "  Batch 4,320  of  5,728.    Elapsed: 1:31:49.\n",
            "  Batch 4,360  of  5,728.    Elapsed: 1:32:40.\n",
            "  Batch 4,400  of  5,728.    Elapsed: 1:33:31.\n",
            "  Batch 4,440  of  5,728.    Elapsed: 1:34:22.\n",
            "  Batch 4,480  of  5,728.    Elapsed: 1:35:13.\n",
            "  Batch 4,520  of  5,728.    Elapsed: 1:36:05.\n",
            "  Batch 4,560  of  5,728.    Elapsed: 1:36:56.\n",
            "  Batch 4,600  of  5,728.    Elapsed: 1:37:47.\n",
            "  Batch 4,640  of  5,728.    Elapsed: 1:38:38.\n",
            "  Batch 4,680  of  5,728.    Elapsed: 1:39:29.\n",
            "  Batch 4,720  of  5,728.    Elapsed: 1:40:20.\n",
            "  Batch 4,760  of  5,728.    Elapsed: 1:41:11.\n",
            "  Batch 4,800  of  5,728.    Elapsed: 1:42:02.\n",
            "  Batch 4,840  of  5,728.    Elapsed: 1:42:53.\n",
            "  Batch 4,880  of  5,728.    Elapsed: 1:43:43.\n",
            "  Batch 4,920  of  5,728.    Elapsed: 1:44:35.\n",
            "  Batch 4,960  of  5,728.    Elapsed: 1:45:26.\n",
            "  Batch 5,000  of  5,728.    Elapsed: 1:46:16.\n",
            "  Batch 5,040  of  5,728.    Elapsed: 1:47:08.\n",
            "  Batch 5,080  of  5,728.    Elapsed: 1:47:59.\n",
            "  Batch 5,120  of  5,728.    Elapsed: 1:48:50.\n",
            "  Batch 5,160  of  5,728.    Elapsed: 1:49:41.\n",
            "  Batch 5,200  of  5,728.    Elapsed: 1:50:32.\n",
            "  Batch 5,240  of  5,728.    Elapsed: 1:51:23.\n",
            "  Batch 5,280  of  5,728.    Elapsed: 1:52:14.\n",
            "  Batch 5,320  of  5,728.    Elapsed: 1:53:05.\n",
            "  Batch 5,360  of  5,728.    Elapsed: 1:53:56.\n",
            "  Batch 5,400  of  5,728.    Elapsed: 1:54:47.\n",
            "  Batch 5,440  of  5,728.    Elapsed: 1:55:38.\n",
            "  Batch 5,480  of  5,728.    Elapsed: 1:56:29.\n",
            "  Batch 5,520  of  5,728.    Elapsed: 1:57:20.\n",
            "  Batch 5,560  of  5,728.    Elapsed: 1:58:11.\n",
            "  Batch 5,600  of  5,728.    Elapsed: 1:59:02.\n",
            "  Batch 5,640  of  5,728.    Elapsed: 1:59:53.\n",
            "  Batch 5,680  of  5,728.    Elapsed: 2:00:44.\n",
            "  Batch 5,720  of  5,728.    Elapsed: 2:01:35.\n",
            "  Average training loss: 1.246275\n",
            "  Average training accuracy: 0.6021\n",
            "  Average training f1: 0.5756\n",
            "  Average training recall: 0.5601\n",
            "--------------------------------------------------\n",
            "  Batch    40  of    716.    Elapsed: 0:00:49.\n",
            "  Batch    80  of    716.    Elapsed: 0:01:37.\n",
            "  Batch   120  of    716.    Elapsed: 0:02:25.\n",
            "  Batch   160  of    716.    Elapsed: 0:03:14.\n",
            "  Batch   200  of    716.    Elapsed: 0:04:02.\n",
            "  Batch   240  of    716.    Elapsed: 0:04:50.\n",
            "  Batch   280  of    716.    Elapsed: 0:05:39.\n",
            "  Batch   320  of    716.    Elapsed: 0:06:27.\n",
            "  Batch   360  of    716.    Elapsed: 0:07:15.\n",
            "  Batch   400  of    716.    Elapsed: 0:08:04.\n",
            "  Batch   440  of    716.    Elapsed: 0:08:52.\n",
            "  Batch   480  of    716.    Elapsed: 0:09:40.\n",
            "  Batch   520  of    716.    Elapsed: 0:10:29.\n",
            "  Batch   560  of    716.    Elapsed: 0:11:17.\n",
            "  Batch   600  of    716.    Elapsed: 0:12:06.\n",
            "  Batch   640  of    716.    Elapsed: 0:12:54.\n",
            "  Batch   680  of    716.    Elapsed: 0:13:43.\n",
            "  Average validation loss: 1.2731\n",
            "  Average validation accuracy: 0.5949\n",
            "  Average validation f1: 0.5660\n",
            "  Average validation recall: 0.5545\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "  Batch    40  of  5,728.    Elapsed: 0:00:51.\n",
            "  Batch    80  of  5,728.    Elapsed: 0:01:43.\n",
            "  Batch   120  of  5,728.    Elapsed: 0:02:33.\n",
            "  Batch   160  of  5,728.    Elapsed: 0:03:25.\n",
            "  Batch   200  of  5,728.    Elapsed: 0:04:15.\n",
            "  Batch   240  of  5,728.    Elapsed: 0:05:06.\n",
            "  Batch   280  of  5,728.    Elapsed: 0:05:57.\n",
            "  Batch   320  of  5,728.    Elapsed: 0:06:48.\n",
            "  Batch   360  of  5,728.    Elapsed: 0:07:39.\n",
            "  Batch   400  of  5,728.    Elapsed: 0:08:31.\n",
            "  Batch   440  of  5,728.    Elapsed: 0:09:22.\n",
            "  Batch   480  of  5,728.    Elapsed: 0:10:13.\n",
            "  Batch   520  of  5,728.    Elapsed: 0:11:04.\n",
            "  Batch   560  of  5,728.    Elapsed: 0:11:55.\n",
            "  Batch   600  of  5,728.    Elapsed: 0:12:46.\n",
            "  Batch   640  of  5,728.    Elapsed: 0:13:37.\n",
            "  Batch   680  of  5,728.    Elapsed: 0:14:28.\n",
            "  Batch   720  of  5,728.    Elapsed: 0:15:20.\n",
            "  Batch   760  of  5,728.    Elapsed: 0:16:11.\n",
            "  Batch   800  of  5,728.    Elapsed: 0:17:02.\n",
            "  Batch   840  of  5,728.    Elapsed: 0:17:53.\n",
            "  Batch   880  of  5,728.    Elapsed: 0:18:44.\n",
            "  Batch   920  of  5,728.    Elapsed: 0:19:35.\n",
            "  Batch   960  of  5,728.    Elapsed: 0:20:26.\n",
            "  Batch 1,000  of  5,728.    Elapsed: 0:21:17.\n",
            "  Batch 1,040  of  5,728.    Elapsed: 0:22:09.\n",
            "  Batch 1,080  of  5,728.    Elapsed: 0:23:00.\n",
            "  Batch 1,120  of  5,728.    Elapsed: 0:23:51.\n",
            "  Batch 1,160  of  5,728.    Elapsed: 0:24:42.\n",
            "  Batch 1,200  of  5,728.    Elapsed: 0:25:33.\n",
            "  Batch 1,240  of  5,728.    Elapsed: 0:26:24.\n",
            "  Batch 1,280  of  5,728.    Elapsed: 0:27:15.\n",
            "  Batch 1,320  of  5,728.    Elapsed: 0:28:06.\n",
            "  Batch 1,360  of  5,728.    Elapsed: 0:28:57.\n",
            "  Batch 1,400  of  5,728.    Elapsed: 0:29:48.\n",
            "  Batch 1,440  of  5,728.    Elapsed: 0:30:39.\n",
            "  Batch 1,480  of  5,728.    Elapsed: 0:31:30.\n",
            "  Batch 1,520  of  5,728.    Elapsed: 0:32:21.\n",
            "  Batch 1,560  of  5,728.    Elapsed: 0:33:12.\n",
            "  Batch 1,600  of  5,728.    Elapsed: 0:34:03.\n",
            "  Batch 1,640  of  5,728.    Elapsed: 0:34:54.\n",
            "  Batch 1,680  of  5,728.    Elapsed: 0:35:45.\n",
            "  Batch 1,720  of  5,728.    Elapsed: 0:36:36.\n",
            "  Batch 1,760  of  5,728.    Elapsed: 0:37:27.\n",
            "  Batch 1,800  of  5,728.    Elapsed: 0:38:18.\n",
            "  Batch 1,840  of  5,728.    Elapsed: 0:39:09.\n",
            "  Batch 1,880  of  5,728.    Elapsed: 0:40:00.\n",
            "  Batch 1,920  of  5,728.    Elapsed: 0:40:52.\n",
            "  Batch 1,960  of  5,728.    Elapsed: 0:41:42.\n",
            "  Batch 2,000  of  5,728.    Elapsed: 0:42:34.\n",
            "  Batch 2,040  of  5,728.    Elapsed: 0:43:25.\n",
            "  Batch 2,080  of  5,728.    Elapsed: 0:44:16.\n",
            "  Batch 2,120  of  5,728.    Elapsed: 0:45:07.\n",
            "  Batch 2,160  of  5,728.    Elapsed: 0:45:58.\n",
            "  Batch 2,200  of  5,728.    Elapsed: 0:46:49.\n",
            "  Batch 2,240  of  5,728.    Elapsed: 0:47:40.\n",
            "  Batch 2,280  of  5,728.    Elapsed: 0:48:31.\n",
            "  Batch 2,320  of  5,728.    Elapsed: 0:49:22.\n",
            "  Batch 2,360  of  5,728.    Elapsed: 0:50:13.\n",
            "  Batch 2,400  of  5,728.    Elapsed: 0:51:04.\n",
            "  Batch 2,440  of  5,728.    Elapsed: 0:51:55.\n",
            "  Batch 2,480  of  5,728.    Elapsed: 0:52:46.\n",
            "  Batch 2,520  of  5,728.    Elapsed: 0:53:37.\n",
            "  Batch 2,560  of  5,728.    Elapsed: 0:54:28.\n",
            "  Batch 2,600  of  5,728.    Elapsed: 0:55:19.\n",
            "  Batch 2,640  of  5,728.    Elapsed: 0:56:10.\n",
            "  Batch 2,680  of  5,728.    Elapsed: 0:57:01.\n",
            "  Batch 2,720  of  5,728.    Elapsed: 0:57:52.\n",
            "  Batch 2,760  of  5,728.    Elapsed: 0:58:43.\n",
            "  Batch 2,800  of  5,728.    Elapsed: 0:59:34.\n",
            "  Batch 2,840  of  5,728.    Elapsed: 1:00:25.\n",
            "  Batch 2,880  of  5,728.    Elapsed: 1:01:16.\n",
            "  Batch 2,920  of  5,728.    Elapsed: 1:02:07.\n",
            "  Batch 2,960  of  5,728.    Elapsed: 1:02:58.\n",
            "  Batch 3,000  of  5,728.    Elapsed: 1:03:49.\n",
            "  Batch 3,040  of  5,728.    Elapsed: 1:04:39.\n",
            "  Batch 3,080  of  5,728.    Elapsed: 1:05:30.\n",
            "  Batch 3,120  of  5,728.    Elapsed: 1:06:21.\n",
            "  Batch 3,160  of  5,728.    Elapsed: 1:07:12.\n",
            "  Batch 3,200  of  5,728.    Elapsed: 1:08:03.\n",
            "  Batch 3,240  of  5,728.    Elapsed: 1:08:54.\n",
            "  Batch 3,280  of  5,728.    Elapsed: 1:09:45.\n",
            "  Batch 3,320  of  5,728.    Elapsed: 1:10:36.\n",
            "  Batch 3,360  of  5,728.    Elapsed: 1:11:27.\n",
            "  Batch 3,400  of  5,728.    Elapsed: 1:12:19.\n",
            "  Batch 3,440  of  5,728.    Elapsed: 1:13:10.\n",
            "  Batch 3,480  of  5,728.    Elapsed: 1:14:01.\n",
            "  Batch 3,520  of  5,728.    Elapsed: 1:14:52.\n",
            "  Batch 3,560  of  5,728.    Elapsed: 1:15:43.\n",
            "  Batch 3,600  of  5,728.    Elapsed: 1:16:34.\n",
            "  Batch 3,640  of  5,728.    Elapsed: 1:17:25.\n",
            "  Batch 3,680  of  5,728.    Elapsed: 1:18:16.\n",
            "  Batch 3,720  of  5,728.    Elapsed: 1:19:07.\n",
            "  Batch 3,760  of  5,728.    Elapsed: 1:19:58.\n",
            "  Batch 3,800  of  5,728.    Elapsed: 1:20:49.\n",
            "  Batch 3,840  of  5,728.    Elapsed: 1:21:40.\n",
            "  Batch 3,880  of  5,728.    Elapsed: 1:22:31.\n",
            "  Batch 3,920  of  5,728.    Elapsed: 1:23:22.\n",
            "  Batch 3,960  of  5,728.    Elapsed: 1:24:13.\n",
            "  Batch 4,000  of  5,728.    Elapsed: 1:25:05.\n",
            "  Batch 4,040  of  5,728.    Elapsed: 1:25:56.\n",
            "  Batch 4,080  of  5,728.    Elapsed: 1:26:47.\n",
            "  Batch 4,120  of  5,728.    Elapsed: 1:27:38.\n",
            "  Batch 4,160  of  5,728.    Elapsed: 1:28:29.\n",
            "  Batch 4,200  of  5,728.    Elapsed: 1:29:20.\n",
            "  Batch 4,240  of  5,728.    Elapsed: 1:30:11.\n",
            "  Batch 4,280  of  5,728.    Elapsed: 1:31:02.\n",
            "  Batch 4,320  of  5,728.    Elapsed: 1:31:53.\n",
            "  Batch 4,360  of  5,728.    Elapsed: 1:32:44.\n",
            "  Batch 4,400  of  5,728.    Elapsed: 1:33:35.\n",
            "  Batch 4,440  of  5,728.    Elapsed: 1:34:25.\n",
            "  Batch 4,480  of  5,728.    Elapsed: 1:35:17.\n",
            "  Batch 4,520  of  5,728.    Elapsed: 1:36:07.\n",
            "  Batch 4,560  of  5,728.    Elapsed: 1:36:59.\n",
            "  Batch 4,600  of  5,728.    Elapsed: 1:37:50.\n",
            "  Batch 4,640  of  5,728.    Elapsed: 1:38:41.\n",
            "  Batch 4,680  of  5,728.    Elapsed: 1:39:32.\n",
            "  Batch 4,720  of  5,728.    Elapsed: 1:40:23.\n",
            "  Batch 4,760  of  5,728.    Elapsed: 1:41:14.\n",
            "  Batch 4,800  of  5,728.    Elapsed: 1:42:04.\n",
            "  Batch 4,840  of  5,728.    Elapsed: 1:42:55.\n",
            "  Batch 4,880  of  5,728.    Elapsed: 1:43:46.\n",
            "  Batch 4,920  of  5,728.    Elapsed: 1:44:37.\n",
            "  Batch 4,960  of  5,728.    Elapsed: 1:45:29.\n",
            "  Batch 5,000  of  5,728.    Elapsed: 1:46:20.\n",
            "  Batch 5,040  of  5,728.    Elapsed: 1:47:11.\n",
            "  Batch 5,080  of  5,728.    Elapsed: 1:48:02.\n",
            "  Batch 5,120  of  5,728.    Elapsed: 1:48:53.\n",
            "  Batch 5,160  of  5,728.    Elapsed: 1:49:44.\n",
            "  Batch 5,200  of  5,728.    Elapsed: 1:50:34.\n",
            "  Batch 5,240  of  5,728.    Elapsed: 1:51:26.\n",
            "  Batch 5,280  of  5,728.    Elapsed: 1:52:17.\n",
            "  Batch 5,320  of  5,728.    Elapsed: 1:53:08.\n",
            "  Batch 5,360  of  5,728.    Elapsed: 1:53:59.\n",
            "  Batch 5,400  of  5,728.    Elapsed: 1:54:50.\n",
            "  Batch 5,440  of  5,728.    Elapsed: 1:55:41.\n",
            "  Batch 5,480  of  5,728.    Elapsed: 1:56:32.\n",
            "  Batch 5,520  of  5,728.    Elapsed: 1:57:23.\n",
            "  Batch 5,560  of  5,728.    Elapsed: 1:58:14.\n",
            "  Batch 5,600  of  5,728.    Elapsed: 1:59:05.\n",
            "  Batch 5,640  of  5,728.    Elapsed: 1:59:56.\n",
            "  Batch 5,680  of  5,728.    Elapsed: 2:00:47.\n",
            "  Batch 5,720  of  5,728.    Elapsed: 2:01:38.\n",
            "  Average training loss: 1.083543\n",
            "  Average training accuracy: 0.6520\n",
            "  Average training f1: 0.6300\n",
            "  Average training recall: 0.6155\n",
            "--------------------------------------------------\n",
            "  Batch    40  of    716.    Elapsed: 0:00:49.\n",
            "  Batch    80  of    716.    Elapsed: 0:01:37.\n",
            "  Batch   120  of    716.    Elapsed: 0:02:26.\n",
            "  Batch   160  of    716.    Elapsed: 0:03:14.\n",
            "  Batch   200  of    716.    Elapsed: 0:04:03.\n",
            "  Batch   240  of    716.    Elapsed: 0:04:51.\n",
            "  Batch   280  of    716.    Elapsed: 0:05:40.\n",
            "  Batch   320  of    716.    Elapsed: 0:06:28.\n",
            "  Batch   360  of    716.    Elapsed: 0:07:17.\n",
            "  Batch   400  of    716.    Elapsed: 0:08:05.\n",
            "  Batch   440  of    716.    Elapsed: 0:08:54.\n",
            "  Batch   480  of    716.    Elapsed: 0:09:42.\n",
            "  Batch   520  of    716.    Elapsed: 0:10:31.\n",
            "  Batch   560  of    716.    Elapsed: 0:11:19.\n",
            "  Batch   600  of    716.    Elapsed: 0:12:08.\n",
            "  Batch   640  of    716.    Elapsed: 0:12:56.\n",
            "  Batch   680  of    716.    Elapsed: 0:13:45.\n",
            "  Average validation loss: 1.2619\n",
            "  Average validation accuracy: 0.6042\n",
            "  Average validation f1: 0.5806\n",
            "  Average validation recall: 0.5631\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "  Batch    40  of  5,728.    Elapsed: 0:00:51.\n",
            "  Batch    80  of  5,728.    Elapsed: 0:01:42.\n",
            "  Batch   120  of  5,728.    Elapsed: 0:02:33.\n",
            "  Batch   160  of  5,728.    Elapsed: 0:03:24.\n",
            "  Batch   200  of  5,728.    Elapsed: 0:04:16.\n",
            "  Batch   240  of  5,728.    Elapsed: 0:05:07.\n",
            "  Batch   280  of  5,728.    Elapsed: 0:05:58.\n",
            "  Batch   320  of  5,728.    Elapsed: 0:06:49.\n",
            "  Batch   360  of  5,728.    Elapsed: 0:07:40.\n",
            "  Batch   400  of  5,728.    Elapsed: 0:08:31.\n",
            "  Batch   440  of  5,728.    Elapsed: 0:09:23.\n",
            "  Batch   480  of  5,728.    Elapsed: 0:10:13.\n",
            "  Batch   520  of  5,728.    Elapsed: 0:11:04.\n",
            "  Batch   560  of  5,728.    Elapsed: 0:11:55.\n",
            "  Batch   600  of  5,728.    Elapsed: 0:12:46.\n",
            "  Batch   640  of  5,728.    Elapsed: 0:13:38.\n",
            "  Batch   680  of  5,728.    Elapsed: 0:14:29.\n",
            "  Batch   720  of  5,728.    Elapsed: 0:15:20.\n",
            "  Batch   760  of  5,728.    Elapsed: 0:16:11.\n",
            "  Batch   800  of  5,728.    Elapsed: 0:17:02.\n",
            "  Batch   840  of  5,728.    Elapsed: 0:17:53.\n",
            "  Batch   880  of  5,728.    Elapsed: 0:18:43.\n",
            "  Batch   920  of  5,728.    Elapsed: 0:19:34.\n",
            "  Batch   960  of  5,728.    Elapsed: 0:20:25.\n",
            "  Batch 1,000  of  5,728.    Elapsed: 0:21:16.\n",
            "  Batch 1,040  of  5,728.    Elapsed: 0:22:07.\n",
            "  Batch 1,080  of  5,728.    Elapsed: 0:22:58.\n",
            "  Batch 1,120  of  5,728.    Elapsed: 0:23:49.\n",
            "  Batch 1,160  of  5,728.    Elapsed: 0:24:40.\n",
            "  Batch 1,200  of  5,728.    Elapsed: 0:25:32.\n",
            "  Batch 1,240  of  5,728.    Elapsed: 0:26:23.\n",
            "  Batch 1,280  of  5,728.    Elapsed: 0:27:14.\n",
            "  Batch 1,320  of  5,728.    Elapsed: 0:28:05.\n",
            "  Batch 1,360  of  5,728.    Elapsed: 0:28:56.\n",
            "  Batch 1,400  of  5,728.    Elapsed: 0:29:47.\n",
            "  Batch 1,440  of  5,728.    Elapsed: 0:30:38.\n",
            "  Batch 1,480  of  5,728.    Elapsed: 0:31:29.\n",
            "  Batch 1,520  of  5,728.    Elapsed: 0:32:20.\n",
            "  Batch 1,560  of  5,728.    Elapsed: 0:33:11.\n",
            "  Batch 1,600  of  5,728.    Elapsed: 0:34:02.\n",
            "  Batch 1,640  of  5,728.    Elapsed: 0:34:53.\n",
            "  Batch 1,680  of  5,728.    Elapsed: 0:35:44.\n",
            "  Batch 1,720  of  5,728.    Elapsed: 0:36:35.\n",
            "  Batch 1,760  of  5,728.    Elapsed: 0:37:26.\n",
            "  Batch 1,800  of  5,728.    Elapsed: 0:38:17.\n",
            "  Batch 1,840  of  5,728.    Elapsed: 0:39:08.\n",
            "  Batch 1,880  of  5,728.    Elapsed: 0:39:59.\n",
            "  Batch 1,920  of  5,728.    Elapsed: 0:40:50.\n",
            "  Batch 1,960  of  5,728.    Elapsed: 0:41:41.\n",
            "  Batch 2,000  of  5,728.    Elapsed: 0:42:32.\n",
            "  Batch 2,040  of  5,728.    Elapsed: 0:43:23.\n",
            "  Batch 2,080  of  5,728.    Elapsed: 0:44:14.\n",
            "  Batch 2,120  of  5,728.    Elapsed: 0:45:05.\n",
            "  Batch 2,160  of  5,728.    Elapsed: 0:45:57.\n",
            "  Batch 2,200  of  5,728.    Elapsed: 0:46:48.\n",
            "  Batch 2,240  of  5,728.    Elapsed: 0:47:39.\n",
            "  Batch 2,280  of  5,728.    Elapsed: 0:48:30.\n",
            "  Batch 2,320  of  5,728.    Elapsed: 0:49:21.\n",
            "  Batch 2,360  of  5,728.    Elapsed: 0:50:12.\n",
            "  Batch 2,400  of  5,728.    Elapsed: 0:51:03.\n",
            "  Batch 2,440  of  5,728.    Elapsed: 0:51:54.\n",
            "  Batch 2,480  of  5,728.    Elapsed: 0:52:45.\n",
            "  Batch 2,520  of  5,728.    Elapsed: 0:53:36.\n",
            "  Batch 2,560  of  5,728.    Elapsed: 0:54:26.\n",
            "  Batch 2,600  of  5,728.    Elapsed: 0:55:18.\n",
            "  Batch 2,640  of  5,728.    Elapsed: 0:56:09.\n",
            "  Batch 2,680  of  5,728.    Elapsed: 0:57:00.\n",
            "  Batch 2,720  of  5,728.    Elapsed: 0:57:51.\n",
            "  Batch 2,760  of  5,728.    Elapsed: 0:58:42.\n",
            "  Batch 2,800  of  5,728.    Elapsed: 0:59:33.\n",
            "  Batch 2,840  of  5,728.    Elapsed: 1:00:24.\n",
            "  Batch 2,880  of  5,728.    Elapsed: 1:01:15.\n",
            "  Batch 2,920  of  5,728.    Elapsed: 1:02:06.\n",
            "  Batch 2,960  of  5,728.    Elapsed: 1:02:57.\n",
            "  Batch 3,000  of  5,728.    Elapsed: 1:03:49.\n",
            "  Batch 3,040  of  5,728.    Elapsed: 1:04:40.\n",
            "  Batch 3,080  of  5,728.    Elapsed: 1:05:31.\n",
            "  Batch 3,120  of  5,728.    Elapsed: 1:06:22.\n",
            "  Batch 3,160  of  5,728.    Elapsed: 1:07:12.\n",
            "  Batch 3,200  of  5,728.    Elapsed: 1:08:04.\n",
            "  Batch 3,240  of  5,728.    Elapsed: 1:08:55.\n",
            "  Batch 3,280  of  5,728.    Elapsed: 1:09:46.\n",
            "  Batch 3,320  of  5,728.    Elapsed: 1:10:37.\n",
            "  Batch 3,360  of  5,728.    Elapsed: 1:11:28.\n",
            "  Batch 3,400  of  5,728.    Elapsed: 1:12:19.\n",
            "  Batch 3,440  of  5,728.    Elapsed: 1:13:11.\n",
            "  Batch 3,480  of  5,728.    Elapsed: 1:14:01.\n",
            "  Batch 3,520  of  5,728.    Elapsed: 1:14:52.\n",
            "  Batch 3,560  of  5,728.    Elapsed: 1:15:44.\n",
            "  Batch 3,600  of  5,728.    Elapsed: 1:16:35.\n",
            "  Batch 3,640  of  5,728.    Elapsed: 1:17:26.\n",
            "  Batch 3,680  of  5,728.    Elapsed: 1:18:17.\n",
            "  Batch 3,720  of  5,728.    Elapsed: 1:19:08.\n",
            "  Batch 3,760  of  5,728.    Elapsed: 1:19:58.\n",
            "  Batch 3,800  of  5,728.    Elapsed: 1:20:49.\n",
            "  Batch 3,840  of  5,728.    Elapsed: 1:21:40.\n",
            "  Batch 3,880  of  5,728.    Elapsed: 1:22:32.\n",
            "  Batch 3,920  of  5,728.    Elapsed: 1:23:23.\n",
            "  Batch 3,960  of  5,728.    Elapsed: 1:24:14.\n",
            "  Batch 4,000  of  5,728.    Elapsed: 1:25:05.\n",
            "  Batch 4,040  of  5,728.    Elapsed: 1:25:56.\n",
            "  Batch 4,080  of  5,728.    Elapsed: 1:26:47.\n",
            "  Batch 4,120  of  5,728.    Elapsed: 1:27:38.\n",
            "  Batch 4,160  of  5,728.    Elapsed: 1:28:29.\n",
            "  Batch 4,200  of  5,728.    Elapsed: 1:29:20.\n",
            "  Batch 4,240  of  5,728.    Elapsed: 1:30:11.\n",
            "  Batch 4,280  of  5,728.    Elapsed: 1:31:02.\n",
            "  Batch 4,320  of  5,728.    Elapsed: 1:31:53.\n",
            "  Batch 4,360  of  5,728.    Elapsed: 1:32:44.\n",
            "  Batch 4,400  of  5,728.    Elapsed: 1:33:35.\n",
            "  Batch 4,440  of  5,728.    Elapsed: 1:34:26.\n",
            "  Batch 4,480  of  5,728.    Elapsed: 1:35:17.\n",
            "  Batch 4,520  of  5,728.    Elapsed: 1:36:08.\n",
            "  Batch 4,560  of  5,728.    Elapsed: 1:36:59.\n",
            "  Batch 4,600  of  5,728.    Elapsed: 1:37:50.\n",
            "  Batch 4,640  of  5,728.    Elapsed: 1:38:41.\n",
            "  Batch 4,680  of  5,728.    Elapsed: 1:39:32.\n",
            "  Batch 4,720  of  5,728.    Elapsed: 1:40:23.\n",
            "  Batch 4,760  of  5,728.    Elapsed: 1:41:14.\n",
            "  Batch 4,800  of  5,728.    Elapsed: 1:42:05.\n",
            "  Batch 4,840  of  5,728.    Elapsed: 1:42:56.\n",
            "  Batch 4,880  of  5,728.    Elapsed: 1:43:47.\n",
            "  Batch 4,920  of  5,728.    Elapsed: 1:44:38.\n",
            "  Batch 4,960  of  5,728.    Elapsed: 1:45:29.\n",
            "  Batch 5,000  of  5,728.    Elapsed: 1:46:20.\n",
            "  Batch 5,040  of  5,728.    Elapsed: 1:47:11.\n",
            "  Batch 5,080  of  5,728.    Elapsed: 1:48:02.\n",
            "  Batch 5,120  of  5,728.    Elapsed: 1:48:53.\n",
            "  Batch 5,160  of  5,728.    Elapsed: 1:49:44.\n",
            "  Batch 5,200  of  5,728.    Elapsed: 1:50:35.\n",
            "  Batch 5,240  of  5,728.    Elapsed: 1:51:26.\n",
            "  Batch 5,280  of  5,728.    Elapsed: 1:52:18.\n",
            "  Batch 5,320  of  5,728.    Elapsed: 1:53:08.\n",
            "  Batch 5,360  of  5,728.    Elapsed: 1:53:59.\n",
            "  Batch 5,400  of  5,728.    Elapsed: 1:54:51.\n",
            "  Batch 5,440  of  5,728.    Elapsed: 1:55:41.\n",
            "  Batch 5,480  of  5,728.    Elapsed: 1:56:32.\n",
            "  Batch 5,520  of  5,728.    Elapsed: 1:57:24.\n",
            "  Batch 5,560  of  5,728.    Elapsed: 1:58:15.\n",
            "  Batch 5,600  of  5,728.    Elapsed: 1:59:06.\n",
            "  Batch 5,640  of  5,728.    Elapsed: 1:59:56.\n",
            "  Batch 5,680  of  5,728.    Elapsed: 2:00:47.\n",
            "  Batch 5,720  of  5,728.    Elapsed: 2:01:39.\n",
            "  Average training loss: 0.960196\n",
            "  Average training accuracy: 0.6922\n",
            "  Average training f1: 0.6733\n",
            "  Average training recall: 0.6597\n",
            "--------------------------------------------------\n",
            "  Batch    40  of    716.    Elapsed: 0:00:48.\n",
            "  Batch    80  of    716.    Elapsed: 0:01:37.\n",
            "  Batch   120  of    716.    Elapsed: 0:02:26.\n",
            "  Batch   160  of    716.    Elapsed: 0:03:14.\n",
            "  Batch   200  of    716.    Elapsed: 0:04:03.\n",
            "  Batch   240  of    716.    Elapsed: 0:04:52.\n",
            "  Batch   280  of    716.    Elapsed: 0:05:40.\n",
            "  Batch   320  of    716.    Elapsed: 0:06:29.\n",
            "  Batch   360  of    716.    Elapsed: 0:07:17.\n",
            "  Batch   400  of    716.    Elapsed: 0:08:06.\n",
            "  Batch   440  of    716.    Elapsed: 0:08:54.\n",
            "  Batch   480  of    716.    Elapsed: 0:09:42.\n",
            "  Batch   520  of    716.    Elapsed: 0:10:31.\n",
            "  Batch   560  of    716.    Elapsed: 0:11:19.\n",
            "  Batch   600  of    716.    Elapsed: 0:12:08.\n",
            "  Batch   640  of    716.    Elapsed: 0:12:56.\n",
            "  Batch   680  of    716.    Elapsed: 0:13:45.\n",
            "  Average validation loss: 1.2750\n",
            "  Average validation accuracy: 0.6060\n",
            "  Average validation f1: 0.5838\n",
            "  Average validation recall: 0.5725\n",
            "--------------------------------------------------\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "  Batch    40  of  5,728.    Elapsed: 0:00:51.\n",
            "  Batch    80  of  5,728.    Elapsed: 0:01:42.\n",
            "  Batch   120  of  5,728.    Elapsed: 0:02:33.\n",
            "  Batch   160  of  5,728.    Elapsed: 0:03:24.\n",
            "  Batch   200  of  5,728.    Elapsed: 0:04:15.\n",
            "  Batch   240  of  5,728.    Elapsed: 0:05:06.\n",
            "  Batch   280  of  5,728.    Elapsed: 0:05:57.\n",
            "  Batch   320  of  5,728.    Elapsed: 0:06:48.\n",
            "  Batch   360  of  5,728.    Elapsed: 0:07:39.\n",
            "  Batch   400  of  5,728.    Elapsed: 0:08:30.\n",
            "  Batch   440  of  5,728.    Elapsed: 0:09:21.\n",
            "  Batch   480  of  5,728.    Elapsed: 0:10:12.\n",
            "  Batch   520  of  5,728.    Elapsed: 0:11:03.\n",
            "  Batch   560  of  5,728.    Elapsed: 0:11:54.\n",
            "  Batch   600  of  5,728.    Elapsed: 0:12:45.\n",
            "  Batch   640  of  5,728.    Elapsed: 0:13:36.\n",
            "  Batch   680  of  5,728.    Elapsed: 0:14:27.\n",
            "  Batch   720  of  5,728.    Elapsed: 0:15:18.\n",
            "  Batch   760  of  5,728.    Elapsed: 0:16:09.\n",
            "  Batch   800  of  5,728.    Elapsed: 0:17:01.\n",
            "  Batch   840  of  5,728.    Elapsed: 0:17:52.\n",
            "  Batch   880  of  5,728.    Elapsed: 0:18:43.\n",
            "  Batch   920  of  5,728.    Elapsed: 0:19:34.\n",
            "  Batch   960  of  5,728.    Elapsed: 0:20:25.\n",
            "  Batch 1,000  of  5,728.    Elapsed: 0:21:16.\n",
            "  Batch 1,040  of  5,728.    Elapsed: 0:22:07.\n",
            "  Batch 1,080  of  5,728.    Elapsed: 0:22:58.\n",
            "  Batch 1,120  of  5,728.    Elapsed: 0:23:49.\n",
            "  Batch 1,160  of  5,728.    Elapsed: 0:24:40.\n",
            "  Batch 1,200  of  5,728.    Elapsed: 0:25:31.\n",
            "  Batch 1,240  of  5,728.    Elapsed: 0:26:22.\n",
            "  Batch 1,280  of  5,728.    Elapsed: 0:27:13.\n",
            "  Batch 1,320  of  5,728.    Elapsed: 0:28:04.\n",
            "  Batch 1,360  of  5,728.    Elapsed: 0:28:55.\n",
            "  Batch 1,400  of  5,728.    Elapsed: 0:29:46.\n",
            "  Batch 1,440  of  5,728.    Elapsed: 0:30:37.\n",
            "  Batch 1,480  of  5,728.    Elapsed: 0:31:28.\n",
            "  Batch 1,520  of  5,728.    Elapsed: 0:32:19.\n",
            "  Batch 1,560  of  5,728.    Elapsed: 0:33:11.\n",
            "  Batch 1,600  of  5,728.    Elapsed: 0:34:01.\n",
            "  Batch 1,640  of  5,728.    Elapsed: 0:34:52.\n",
            "  Batch 1,680  of  5,728.    Elapsed: 0:35:43.\n",
            "  Batch 1,720  of  5,728.    Elapsed: 0:36:34.\n",
            "  Batch 1,760  of  5,728.    Elapsed: 0:37:25.\n",
            "  Batch 1,800  of  5,728.    Elapsed: 0:38:17.\n",
            "  Batch 1,840  of  5,728.    Elapsed: 0:39:08.\n",
            "  Batch 1,880  of  5,728.    Elapsed: 0:39:58.\n",
            "  Batch 1,920  of  5,728.    Elapsed: 0:40:49.\n",
            "  Batch 1,960  of  5,728.    Elapsed: 0:41:40.\n",
            "  Batch 2,000  of  5,728.    Elapsed: 0:42:31.\n",
            "  Batch 2,040  of  5,728.    Elapsed: 0:43:22.\n",
            "  Batch 2,080  of  5,728.    Elapsed: 0:44:13.\n",
            "  Batch 2,120  of  5,728.    Elapsed: 0:45:05.\n",
            "  Batch 2,160  of  5,728.    Elapsed: 0:45:56.\n",
            "  Batch 2,200  of  5,728.    Elapsed: 0:46:47.\n",
            "  Batch 2,240  of  5,728.    Elapsed: 0:47:38.\n",
            "  Batch 2,280  of  5,728.    Elapsed: 0:48:29.\n",
            "  Batch 2,320  of  5,728.    Elapsed: 0:49:20.\n",
            "  Batch 2,360  of  5,728.    Elapsed: 0:50:11.\n",
            "  Batch 2,400  of  5,728.    Elapsed: 0:51:03.\n",
            "  Batch 2,440  of  5,728.    Elapsed: 0:51:54.\n",
            "  Batch 2,480  of  5,728.    Elapsed: 0:52:44.\n",
            "  Batch 2,520  of  5,728.    Elapsed: 0:53:35.\n",
            "  Batch 2,560  of  5,728.    Elapsed: 0:54:27.\n",
            "  Batch 2,600  of  5,728.    Elapsed: 0:55:18.\n",
            "  Batch 2,640  of  5,728.    Elapsed: 0:56:09.\n",
            "  Batch 2,680  of  5,728.    Elapsed: 0:57:00.\n",
            "  Batch 2,720  of  5,728.    Elapsed: 0:57:51.\n",
            "  Batch 2,760  of  5,728.    Elapsed: 0:58:43.\n",
            "  Batch 2,800  of  5,728.    Elapsed: 0:59:33.\n",
            "  Batch 2,840  of  5,728.    Elapsed: 1:00:24.\n",
            "  Batch 2,880  of  5,728.    Elapsed: 1:01:15.\n",
            "  Batch 2,920  of  5,728.    Elapsed: 1:02:06.\n",
            "  Batch 2,960  of  5,728.    Elapsed: 1:02:57.\n",
            "  Batch 3,000  of  5,728.    Elapsed: 1:03:48.\n",
            "  Batch 3,040  of  5,728.    Elapsed: 1:04:39.\n",
            "  Batch 3,080  of  5,728.    Elapsed: 1:05:30.\n",
            "  Batch 3,120  of  5,728.    Elapsed: 1:06:21.\n",
            "  Batch 3,160  of  5,728.    Elapsed: 1:07:12.\n",
            "  Batch 3,200  of  5,728.    Elapsed: 1:08:03.\n",
            "  Batch 3,240  of  5,728.    Elapsed: 1:08:54.\n",
            "  Batch 3,280  of  5,728.    Elapsed: 1:09:45.\n",
            "  Batch 3,320  of  5,728.    Elapsed: 1:10:37.\n",
            "  Batch 3,360  of  5,728.    Elapsed: 1:11:28.\n",
            "  Batch 3,400  of  5,728.    Elapsed: 1:12:19.\n",
            "  Batch 3,440  of  5,728.    Elapsed: 1:13:10.\n",
            "  Batch 3,480  of  5,728.    Elapsed: 1:14:01.\n",
            "  Batch 3,520  of  5,728.    Elapsed: 1:14:52.\n",
            "  Batch 3,560  of  5,728.    Elapsed: 1:15:43.\n",
            "  Batch 3,600  of  5,728.    Elapsed: 1:16:34.\n",
            "  Batch 3,640  of  5,728.    Elapsed: 1:17:25.\n",
            "  Batch 3,680  of  5,728.    Elapsed: 1:18:16.\n",
            "  Batch 3,720  of  5,728.    Elapsed: 1:19:07.\n",
            "  Batch 3,760  of  5,728.    Elapsed: 1:19:58.\n",
            "  Batch 3,800  of  5,728.    Elapsed: 1:20:49.\n",
            "  Batch 3,840  of  5,728.    Elapsed: 1:21:40.\n",
            "  Batch 3,880  of  5,728.    Elapsed: 1:22:31.\n",
            "  Batch 3,920  of  5,728.    Elapsed: 1:23:22.\n",
            "  Batch 3,960  of  5,728.    Elapsed: 1:24:13.\n",
            "  Batch 4,000  of  5,728.    Elapsed: 1:25:04.\n",
            "  Batch 4,040  of  5,728.    Elapsed: 1:25:55.\n",
            "  Batch 4,080  of  5,728.    Elapsed: 1:26:46.\n",
            "  Batch 4,120  of  5,728.    Elapsed: 1:27:37.\n",
            "  Batch 4,160  of  5,728.    Elapsed: 1:28:28.\n",
            "  Batch 4,200  of  5,728.    Elapsed: 1:29:20.\n",
            "  Batch 4,240  of  5,728.    Elapsed: 1:30:11.\n",
            "  Batch 4,280  of  5,728.    Elapsed: 1:31:02.\n",
            "  Batch 4,320  of  5,728.    Elapsed: 1:31:53.\n",
            "  Batch 4,360  of  5,728.    Elapsed: 1:32:44.\n",
            "  Batch 4,400  of  5,728.    Elapsed: 1:33:35.\n",
            "  Batch 4,440  of  5,728.    Elapsed: 1:34:26.\n",
            "  Batch 4,480  of  5,728.    Elapsed: 1:35:17.\n",
            "  Batch 4,520  of  5,728.    Elapsed: 1:36:08.\n",
            "  Batch 4,560  of  5,728.    Elapsed: 1:36:59.\n",
            "  Batch 4,600  of  5,728.    Elapsed: 1:37:50.\n",
            "  Batch 4,640  of  5,728.    Elapsed: 1:38:41.\n",
            "  Batch 4,680  of  5,728.    Elapsed: 1:39:32.\n",
            "  Batch 4,720  of  5,728.    Elapsed: 1:40:23.\n",
            "  Batch 4,760  of  5,728.    Elapsed: 1:41:14.\n",
            "  Batch 4,800  of  5,728.    Elapsed: 1:42:05.\n",
            "  Batch 4,840  of  5,728.    Elapsed: 1:42:56.\n",
            "  Batch 4,880  of  5,728.    Elapsed: 1:43:47.\n",
            "  Batch 4,920  of  5,728.    Elapsed: 1:44:38.\n",
            "  Batch 4,960  of  5,728.    Elapsed: 1:45:29.\n",
            "  Batch 5,000  of  5,728.    Elapsed: 1:46:20.\n",
            "  Batch 5,040  of  5,728.    Elapsed: 1:47:11.\n",
            "  Batch 5,080  of  5,728.    Elapsed: 1:48:02.\n",
            "  Batch 5,120  of  5,728.    Elapsed: 1:48:53.\n",
            "  Batch 5,160  of  5,728.    Elapsed: 1:49:44.\n",
            "  Batch 5,200  of  5,728.    Elapsed: 1:50:35.\n",
            "  Batch 5,240  of  5,728.    Elapsed: 1:51:26.\n",
            "  Batch 5,280  of  5,728.    Elapsed: 1:52:17.\n",
            "  Batch 5,320  of  5,728.    Elapsed: 1:53:08.\n",
            "  Batch 5,360  of  5,728.    Elapsed: 1:53:59.\n",
            "  Batch 5,400  of  5,728.    Elapsed: 1:54:50.\n",
            "  Batch 5,440  of  5,728.    Elapsed: 1:55:41.\n",
            "  Batch 5,480  of  5,728.    Elapsed: 1:56:32.\n",
            "  Batch 5,520  of  5,728.    Elapsed: 1:57:24.\n",
            "  Batch 5,560  of  5,728.    Elapsed: 1:58:15.\n",
            "  Batch 5,600  of  5,728.    Elapsed: 1:59:06.\n",
            "  Batch 5,640  of  5,728.    Elapsed: 1:59:57.\n",
            "  Batch 5,680  of  5,728.    Elapsed: 2:00:48.\n",
            "  Batch 5,720  of  5,728.    Elapsed: 2:01:39.\n",
            "  Average training loss: 0.874480\n",
            "  Average training accuracy: 0.7198\n",
            "  Average training f1: 0.7025\n",
            "  Average training recall: 0.6898\n",
            "--------------------------------------------------\n",
            "  Batch    40  of    716.    Elapsed: 0:00:49.\n",
            "  Batch    80  of    716.    Elapsed: 0:01:37.\n",
            "  Batch   120  of    716.    Elapsed: 0:02:26.\n",
            "  Batch   160  of    716.    Elapsed: 0:03:15.\n",
            "  Batch   200  of    716.    Elapsed: 0:04:03.\n",
            "  Batch   240  of    716.    Elapsed: 0:04:51.\n",
            "  Batch   280  of    716.    Elapsed: 0:05:40.\n",
            "  Batch   320  of    716.    Elapsed: 0:06:29.\n",
            "  Batch   360  of    716.    Elapsed: 0:07:17.\n",
            "  Batch   400  of    716.    Elapsed: 0:08:06.\n",
            "  Batch   440  of    716.    Elapsed: 0:08:54.\n",
            "  Batch   480  of    716.    Elapsed: 0:09:43.\n",
            "  Batch   520  of    716.    Elapsed: 0:10:32.\n",
            "  Batch   560  of    716.    Elapsed: 0:11:20.\n",
            "  Batch   600  of    716.    Elapsed: 0:12:09.\n",
            "  Batch   640  of    716.    Elapsed: 0:12:57.\n",
            "  Batch   680  of    716.    Elapsed: 0:13:46.\n",
            "  Average validation loss: 1.2925\n",
            "  Average validation accuracy: 0.6077\n",
            "  Average validation f1: 0.5853\n",
            "  Average validation recall: 0.5738\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on Test"
      ],
      "metadata": {
        "id": "3VuIbDmx1B92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_large,actual = dialectUtils.Batchpredict(BERTmodel_large,test_loader_large)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd16942-8ef2-486f-9108-972e30da865a",
        "id": "J-l7c8e62UBY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.get_report(pred_large,actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b104b4cb-d366-49f3-e545-490d72afdad0",
        "id": "UEmsOjUr2UBY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.86      0.92      0.89      5756\n",
            "          PL       0.58      0.78      0.66      4368\n",
            "          KW       0.62      0.79      0.69      4200\n",
            "          LY       0.78      0.87      0.83      3647\n",
            "          QA       0.74      0.55      0.63      3105\n",
            "          JO       0.63      0.49      0.55      2784\n",
            "          LB       0.85      0.77      0.81      2757\n",
            "          SA       0.64      0.68      0.66      2678\n",
            "          AE       0.65      0.61      0.63      2620\n",
            "          BH       0.53      0.55      0.54      2612\n",
            "          OM       0.64      0.61      0.63      1904\n",
            "          SY       0.72      0.55      0.62      1621\n",
            "          DZ       0.82      0.66      0.73      1614\n",
            "          IQ       0.87      0.70      0.78      1548\n",
            "          SD       0.92      0.74      0.82      1438\n",
            "          MA       0.91      0.71      0.80      1153\n",
            "          YE       0.57      0.47      0.51       988\n",
            "          TN       0.73      0.65      0.69       923\n",
            "\n",
            "    accuracy                           0.71     45716\n",
            "   macro avg       0.73      0.67      0.69     45716\n",
            "weighted avg       0.72      0.71      0.71     45716\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Large Model"
      ],
      "metadata": {
        "id": "QtLoWJjM1FA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/Aim_NLP_Task/BERT_Fine_Tuning_dialect_large_061'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = BERTmodel_large.module if hasattr(BERTmodel_large, 'module') else BERTmodel_large  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer_obj_large.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "metadata": {
        "id": "596R51TFtXq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Aim_NLP_Task/Models_Weight/model_large_0.61.pth\"\n",
        "torch.save(BERTmodel_large.cpu().state_dict(), path) # saving model\n",
        "BERTmodel_large.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwLW3-mCuN7J",
        "outputId": "aa5b30e8-fde4-49e9-ace2-55f82e408e2d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pretrained Model"
      ],
      "metadata": {
        "id": "98m2ItehmotF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir_large=\"/content/drive/MyDrive/Aim_NLP_Task/BERT_Fine_Tuning_dialect_large_0.61\"\n",
        "test_tweets,test_labels = dialectUtils.read_csv(\"../Data/preProcessedTweets_testF.csv\",\n",
        "                                                  \"text_preprocessed\",\"label\")"
      ],
      "metadata": {
        "id": "mnmfnOTWuwaQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_class_large = BertTokenizer.from_pretrained(output_dir_large)\n",
        "load_BERTmodel_large = BertForSequenceClassification.from_pretrained(output_dir_large)"
      ],
      "metadata": {
        "id": "RSYnf5fnlETI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_BERTmodel_large.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moucgW3g4lsC",
        "outputId": "1b0f1fb1-ce13-41c5-ad58-29b7f84433f2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_large  = tokenizer_class_large.bert_tokenize_data(test_tweets,test_labels)\n",
        "test_loader_large=dialectUtils.create_bert_dataloader(test_data_large,valid=None,batch_size=64,\n",
        "                                                split_train=False,test=True)"
      ],
      "metadata": {
        "id": "34hEdZYw1p4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_large,actual = dialectUtils.Batchpredict(BERTmodel_large,test_loader_large)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xupXcsRLSqB1",
        "outputId": "1bd16942-8ef2-486f-9108-972e30da865a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialectUtils.get_report(pred_large,actual)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqe6sTg2SqGf",
        "outputId": "b104b4cb-d366-49f3-e545-490d72afdad0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          EG       0.86      0.92      0.89      5756\n",
            "          PL       0.58      0.78      0.66      4368\n",
            "          KW       0.62      0.79      0.69      4200\n",
            "          LY       0.78      0.87      0.83      3647\n",
            "          QA       0.74      0.55      0.63      3105\n",
            "          JO       0.63      0.49      0.55      2784\n",
            "          LB       0.85      0.77      0.81      2757\n",
            "          SA       0.64      0.68      0.66      2678\n",
            "          AE       0.65      0.61      0.63      2620\n",
            "          BH       0.53      0.55      0.54      2612\n",
            "          OM       0.64      0.61      0.63      1904\n",
            "          SY       0.72      0.55      0.62      1621\n",
            "          DZ       0.82      0.66      0.73      1614\n",
            "          IQ       0.87      0.70      0.78      1548\n",
            "          SD       0.92      0.74      0.82      1438\n",
            "          MA       0.91      0.71      0.80      1153\n",
            "          YE       0.57      0.47      0.51       988\n",
            "          TN       0.73      0.65      0.69       923\n",
            "\n",
            "    accuracy                           0.71     45716\n",
            "   macro avg       0.73      0.67      0.69     45716\n",
            "weighted avg       0.72      0.71      0.71     45716\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___________________________________________________________________"
      ],
      "metadata": {
        "id": "ntmGaUmyjlq9"
      }
    }
  ]
}